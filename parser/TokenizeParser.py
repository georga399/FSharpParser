# Generated from Tokenize.g4 by ANTLR 4.13.1
# encoding: utf-8
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
	from typing import TextIO
else:
	from typing.io import TextIO

def serializedATN():
    return [
        4,1,42,203,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,7,
        6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,13,
        2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,20,
        7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,26,
        2,27,7,27,2,28,7,28,2,29,7,29,1,0,1,0,1,0,5,0,64,8,0,10,0,12,0,67,
        9,0,1,1,1,1,1,2,1,2,1,3,1,3,1,4,1,4,1,5,1,5,1,6,1,6,1,7,1,7,1,8,
        1,8,1,9,3,9,86,8,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,5,9,95,8,9,10,9,12,
        9,98,9,9,1,9,1,9,1,10,1,10,1,10,1,10,1,10,1,10,1,11,1,11,4,11,110,
        8,11,11,11,12,11,111,1,11,1,11,1,12,1,12,1,13,1,13,1,14,1,14,1,15,
        1,15,1,16,1,16,1,17,1,17,1,18,1,18,4,18,130,8,18,11,18,12,18,131,
        1,18,1,18,1,18,1,19,1,19,1,19,3,19,140,8,19,1,20,1,20,4,20,144,8,
        20,11,20,12,20,145,1,20,1,20,4,20,150,8,20,11,20,12,20,151,1,20,
        1,20,4,20,156,8,20,11,20,12,20,157,1,20,1,20,4,20,162,8,20,11,20,
        12,20,163,5,20,166,8,20,10,20,12,20,169,9,20,1,20,1,20,3,20,173,
        8,20,1,21,1,21,1,22,1,22,1,23,1,23,1,24,1,24,1,25,1,25,1,26,1,26,
        1,27,1,27,1,28,1,28,1,28,1,28,3,28,193,8,28,1,29,5,29,196,8,29,10,
        29,12,29,199,9,29,1,29,1,29,1,29,0,0,30,0,2,4,6,8,10,12,14,16,18,
        20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,0,0,
        190,0,60,1,0,0,0,2,68,1,0,0,0,4,70,1,0,0,0,6,72,1,0,0,0,8,74,1,0,
        0,0,10,76,1,0,0,0,12,78,1,0,0,0,14,80,1,0,0,0,16,82,1,0,0,0,18,85,
        1,0,0,0,20,101,1,0,0,0,22,107,1,0,0,0,24,115,1,0,0,0,26,117,1,0,
        0,0,28,119,1,0,0,0,30,121,1,0,0,0,32,123,1,0,0,0,34,125,1,0,0,0,
        36,127,1,0,0,0,38,136,1,0,0,0,40,141,1,0,0,0,42,174,1,0,0,0,44,176,
        1,0,0,0,46,178,1,0,0,0,48,180,1,0,0,0,50,182,1,0,0,0,52,184,1,0,
        0,0,54,186,1,0,0,0,56,192,1,0,0,0,58,197,1,0,0,0,60,65,5,17,0,0,
        61,62,5,1,0,0,62,64,5,17,0,0,63,61,1,0,0,0,64,67,1,0,0,0,65,63,1,
        0,0,0,65,66,1,0,0,0,66,1,1,0,0,0,67,65,1,0,0,0,68,69,5,18,0,0,69,
        3,1,0,0,0,70,71,5,19,0,0,71,5,1,0,0,0,72,73,5,24,0,0,73,7,1,0,0,
        0,74,75,5,23,0,0,75,9,1,0,0,0,76,77,5,21,0,0,77,11,1,0,0,0,78,79,
        5,34,0,0,79,13,1,0,0,0,80,81,5,20,0,0,81,15,1,0,0,0,82,83,5,32,0,
        0,83,17,1,0,0,0,84,86,3,16,8,0,85,84,1,0,0,0,85,86,1,0,0,0,86,87,
        1,0,0,0,87,96,5,2,0,0,88,89,5,3,0,0,89,90,3,56,28,0,90,91,5,4,0,
        0,91,95,1,0,0,0,92,95,3,14,7,0,93,95,5,21,0,0,94,88,1,0,0,0,94,92,
        1,0,0,0,94,93,1,0,0,0,95,98,1,0,0,0,96,94,1,0,0,0,96,97,1,0,0,0,
        97,99,1,0,0,0,98,96,1,0,0,0,99,100,5,2,0,0,100,19,1,0,0,0,101,102,
        5,5,0,0,102,103,5,6,0,0,103,104,3,0,0,0,104,105,5,7,0,0,105,106,
        5,8,0,0,106,21,1,0,0,0,107,109,5,9,0,0,108,110,3,56,28,0,109,108,
        1,0,0,0,110,111,1,0,0,0,111,109,1,0,0,0,111,112,1,0,0,0,112,113,
        1,0,0,0,113,114,5,10,0,0,114,23,1,0,0,0,115,116,5,25,0,0,116,25,
        1,0,0,0,117,118,5,26,0,0,118,27,1,0,0,0,119,120,5,27,0,0,120,29,
        1,0,0,0,121,122,5,28,0,0,122,31,1,0,0,0,123,124,5,29,0,0,124,33,
        1,0,0,0,125,126,5,30,0,0,126,35,1,0,0,0,127,129,5,31,0,0,128,130,
        3,56,28,0,129,128,1,0,0,0,130,131,1,0,0,0,131,129,1,0,0,0,131,132,
        1,0,0,0,132,133,1,0,0,0,133,134,5,35,0,0,134,135,3,56,28,0,135,37,
        1,0,0,0,136,139,5,33,0,0,137,140,3,22,11,0,138,140,3,0,0,0,139,137,
        1,0,0,0,139,138,1,0,0,0,140,39,1,0,0,0,141,143,5,11,0,0,142,144,
        3,56,28,0,143,142,1,0,0,0,144,145,1,0,0,0,145,143,1,0,0,0,145,146,
        1,0,0,0,146,147,1,0,0,0,147,149,5,12,0,0,148,150,3,56,28,0,149,148,
        1,0,0,0,150,151,1,0,0,0,151,149,1,0,0,0,151,152,1,0,0,0,152,167,
        1,0,0,0,153,155,5,13,0,0,154,156,3,56,28,0,155,154,1,0,0,0,156,157,
        1,0,0,0,157,155,1,0,0,0,157,158,1,0,0,0,158,159,1,0,0,0,159,161,
        5,12,0,0,160,162,3,56,28,0,161,160,1,0,0,0,162,163,1,0,0,0,163,161,
        1,0,0,0,163,164,1,0,0,0,164,166,1,0,0,0,165,153,1,0,0,0,166,169,
        1,0,0,0,167,165,1,0,0,0,167,168,1,0,0,0,168,172,1,0,0,0,169,167,
        1,0,0,0,170,171,5,14,0,0,171,173,3,56,28,0,172,170,1,0,0,0,172,173,
        1,0,0,0,173,41,1,0,0,0,174,175,5,36,0,0,175,43,1,0,0,0,176,177,5,
        38,0,0,177,45,1,0,0,0,178,179,5,39,0,0,179,47,1,0,0,0,180,181,5,
        37,0,0,181,49,1,0,0,0,182,183,5,40,0,0,183,51,1,0,0,0,184,185,5,
        41,0,0,185,53,1,0,0,0,186,187,5,42,0,0,187,55,1,0,0,0,188,193,3,
        0,0,0,189,193,3,2,1,0,190,193,3,6,3,0,191,193,3,20,10,0,192,188,
        1,0,0,0,192,189,1,0,0,0,192,190,1,0,0,0,192,191,1,0,0,0,193,57,1,
        0,0,0,194,196,3,56,28,0,195,194,1,0,0,0,196,199,1,0,0,0,197,195,
        1,0,0,0,197,198,1,0,0,0,198,200,1,0,0,0,199,197,1,0,0,0,200,201,
        5,0,0,1,201,59,1,0,0,0,15,65,85,94,96,111,131,139,145,151,157,163,
        167,172,192,197
    ]

class TokenizeParser ( Parser ):

    grammarFileName = "Tokenize.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ "<INVALID>", "'.'", "'\"'", "'{'", "'}'", "'['", "'<'", 
                     "'>'", "']'", "'('", "')'", "'if'", "'then'", "'elif'", 
                     "'else'", "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "'rec'", "'public'", "'private'", 
                     "'internal'", "'mutable'", "'let'", "'fun'", "'$'", 
                     "':'", "'_'", "'->'", "'+'", "'-'", "'*'", "'/'", "'**'", 
                     "'%'", "'='" ]

    symbolicNames = [ "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                      "<INVALID>", "<INVALID>", "<INVALID>", "WHITE_SPACE", 
                      "COMMENT", "IDENTIFIER", "INT", "FLOAT", "INTERPOLATIONSIGN", 
                      "CHAR", "ESC", "BOOL", "UNIT", "REC", "PUBLIC", "PRIVATE", 
                      "INTERNAL", "MUTABLE", "LET", "FUN", "DOLLAR", "COLON", 
                      "MISSING_ARG", "RIGHT_ARROW", "ADD", "MINUS", "MUL", 
                      "DIV", "POW", "MOD", "EQUAL" ]

    RULE_dotIentifier = 0
    RULE_int = 1
    RULE_float = 2
    RULE_unit = 3
    RULE_bool = 4
    RULE_char = 5
    RULE_missing_arg = 6
    RULE_interpolationSign = 7
    RULE_dollar = 8
    RULE_string = 9
    RULE_attribute = 10
    RULE_round_brackets = 11
    RULE_rec = 12
    RULE_public = 13
    RULE_private = 14
    RULE_internal = 15
    RULE_mutable = 16
    RULE_let = 17
    RULE_fun = 18
    RULE_typezation = 19
    RULE_if_then_elif_else = 20
    RULE_add = 21
    RULE_mul = 22
    RULE_div = 23
    RULE_minus = 24
    RULE_pow = 25
    RULE_mod = 26
    RULE_equal = 27
    RULE_expression = 28
    RULE_exprs = 29

    ruleNames =  [ "dotIentifier", "int", "float", "unit", "bool", "char", 
                   "missing_arg", "interpolationSign", "dollar", "string", 
                   "attribute", "round_brackets", "rec", "public", "private", 
                   "internal", "mutable", "let", "fun", "typezation", "if_then_elif_else", 
                   "add", "mul", "div", "minus", "pow", "mod", "equal", 
                   "expression", "exprs" ]

    EOF = Token.EOF
    T__0=1
    T__1=2
    T__2=3
    T__3=4
    T__4=5
    T__5=6
    T__6=7
    T__7=8
    T__8=9
    T__9=10
    T__10=11
    T__11=12
    T__12=13
    T__13=14
    WHITE_SPACE=15
    COMMENT=16
    IDENTIFIER=17
    INT=18
    FLOAT=19
    INTERPOLATIONSIGN=20
    CHAR=21
    ESC=22
    BOOL=23
    UNIT=24
    REC=25
    PUBLIC=26
    PRIVATE=27
    INTERNAL=28
    MUTABLE=29
    LET=30
    FUN=31
    DOLLAR=32
    COLON=33
    MISSING_ARG=34
    RIGHT_ARROW=35
    ADD=36
    MINUS=37
    MUL=38
    DIV=39
    POW=40
    MOD=41
    EQUAL=42

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.13.1")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None




    class DotIentifierContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def IDENTIFIER(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.IDENTIFIER)
            else:
                return self.getToken(TokenizeParser.IDENTIFIER, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_dotIentifier

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDotIentifier" ):
                listener.enterDotIentifier(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDotIentifier" ):
                listener.exitDotIentifier(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDotIentifier" ):
                return visitor.visitDotIentifier(self)
            else:
                return visitor.visitChildren(self)




    def dotIentifier(self):

        localctx = TokenizeParser.DotIentifierContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_dotIentifier)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 60
            self.match(TokenizeParser.IDENTIFIER)
            self.state = 65
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==1:
                self.state = 61
                self.match(TokenizeParser.T__0)
                self.state = 62
                self.match(TokenizeParser.IDENTIFIER)
                self.state = 67
                self._errHandler.sync(self)
                _la = self._input.LA(1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class IntContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INT(self):
            return self.getToken(TokenizeParser.INT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_int

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInt" ):
                listener.enterInt(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInt" ):
                listener.exitInt(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInt" ):
                return visitor.visitInt(self)
            else:
                return visitor.visitChildren(self)




    def int_(self):

        localctx = TokenizeParser.IntContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_int)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 68
            self.match(TokenizeParser.INT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class FloatContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def FLOAT(self):
            return self.getToken(TokenizeParser.FLOAT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_float

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFloat" ):
                listener.enterFloat(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFloat" ):
                listener.exitFloat(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitFloat" ):
                return visitor.visitFloat(self)
            else:
                return visitor.visitChildren(self)




    def float_(self):

        localctx = TokenizeParser.FloatContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_float)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 70
            self.match(TokenizeParser.FLOAT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class UnitContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def UNIT(self):
            return self.getToken(TokenizeParser.UNIT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_unit

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterUnit" ):
                listener.enterUnit(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitUnit" ):
                listener.exitUnit(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitUnit" ):
                return visitor.visitUnit(self)
            else:
                return visitor.visitChildren(self)




    def unit(self):

        localctx = TokenizeParser.UnitContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_unit)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 72
            self.match(TokenizeParser.UNIT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class BoolContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def BOOL(self):
            return self.getToken(TokenizeParser.BOOL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_bool

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterBool" ):
                listener.enterBool(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitBool" ):
                listener.exitBool(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitBool" ):
                return visitor.visitBool(self)
            else:
                return visitor.visitChildren(self)




    def bool_(self):

        localctx = TokenizeParser.BoolContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_bool)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 74
            self.match(TokenizeParser.BOOL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class CharContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def CHAR(self):
            return self.getToken(TokenizeParser.CHAR, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_char

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterChar" ):
                listener.enterChar(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitChar" ):
                listener.exitChar(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitChar" ):
                return visitor.visitChar(self)
            else:
                return visitor.visitChildren(self)




    def char(self):

        localctx = TokenizeParser.CharContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_char)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 76
            self.match(TokenizeParser.CHAR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Missing_argContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MISSING_ARG(self):
            return self.getToken(TokenizeParser.MISSING_ARG, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_missing_arg

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMissing_arg" ):
                listener.enterMissing_arg(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMissing_arg" ):
                listener.exitMissing_arg(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMissing_arg" ):
                return visitor.visitMissing_arg(self)
            else:
                return visitor.visitChildren(self)




    def missing_arg(self):

        localctx = TokenizeParser.Missing_argContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_missing_arg)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 78
            self.match(TokenizeParser.MISSING_ARG)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class InterpolationSignContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INTERPOLATIONSIGN(self):
            return self.getToken(TokenizeParser.INTERPOLATIONSIGN, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_interpolationSign

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInterpolationSign" ):
                listener.enterInterpolationSign(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInterpolationSign" ):
                listener.exitInterpolationSign(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInterpolationSign" ):
                return visitor.visitInterpolationSign(self)
            else:
                return visitor.visitChildren(self)




    def interpolationSign(self):

        localctx = TokenizeParser.InterpolationSignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_interpolationSign)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 80
            self.match(TokenizeParser.INTERPOLATIONSIGN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class DollarContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def DOLLAR(self):
            return self.getToken(TokenizeParser.DOLLAR, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_dollar

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDollar" ):
                listener.enterDollar(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDollar" ):
                listener.exitDollar(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDollar" ):
                return visitor.visitDollar(self)
            else:
                return visitor.visitChildren(self)




    def dollar(self):

        localctx = TokenizeParser.DollarContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_dollar)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 82
            self.match(TokenizeParser.DOLLAR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class StringContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def dollar(self):
            return self.getTypedRuleContext(TokenizeParser.DollarContext,0)


        def interpolationSign(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.InterpolationSignContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.InterpolationSignContext,i)


        def CHAR(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.CHAR)
            else:
                return self.getToken(TokenizeParser.CHAR, i)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_string

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterString" ):
                listener.enterString(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitString" ):
                listener.exitString(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitString" ):
                return visitor.visitString(self)
            else:
                return visitor.visitChildren(self)




    def string(self):

        localctx = TokenizeParser.StringContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_string)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 85
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==32:
                self.state = 84
                self.dollar()


            self.state = 87
            self.match(TokenizeParser.T__1)
            self.state = 96
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & 3145736) != 0):
                self.state = 94
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [3]:
                    self.state = 88
                    self.match(TokenizeParser.T__2)
                    self.state = 89
                    self.expression()
                    self.state = 90
                    self.match(TokenizeParser.T__3)
                    pass
                elif token in [20]:
                    self.state = 92
                    self.interpolationSign()
                    pass
                elif token in [21]:
                    self.state = 93
                    self.match(TokenizeParser.CHAR)
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 98
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 99
            self.match(TokenizeParser.T__1)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AttributeContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_attribute

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAttribute" ):
                listener.enterAttribute(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAttribute" ):
                listener.exitAttribute(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitAttribute" ):
                return visitor.visitAttribute(self)
            else:
                return visitor.visitChildren(self)




    def attribute(self):

        localctx = TokenizeParser.AttributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_attribute)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 101
            self.match(TokenizeParser.T__4)
            self.state = 102
            self.match(TokenizeParser.T__5)
            self.state = 103
            self.dotIentifier()
            self.state = 104
            self.match(TokenizeParser.T__6)
            self.state = 105
            self.match(TokenizeParser.T__7)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Round_bracketsContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_round_brackets

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRound_brackets" ):
                listener.enterRound_brackets(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRound_brackets" ):
                listener.exitRound_brackets(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitRound_brackets" ):
                return visitor.visitRound_brackets(self)
            else:
                return visitor.visitChildren(self)




    def round_brackets(self):

        localctx = TokenizeParser.Round_bracketsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_round_brackets)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 107
            self.match(TokenizeParser.T__8)
            self.state = 109 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 108
                self.expression()
                self.state = 111 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & 17170464) != 0)):
                    break

            self.state = 113
            self.match(TokenizeParser.T__9)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class RecContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def REC(self):
            return self.getToken(TokenizeParser.REC, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_rec

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRec" ):
                listener.enterRec(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRec" ):
                listener.exitRec(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitRec" ):
                return visitor.visitRec(self)
            else:
                return visitor.visitChildren(self)




    def rec(self):

        localctx = TokenizeParser.RecContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_rec)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 115
            self.match(TokenizeParser.REC)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class PublicContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def PUBLIC(self):
            return self.getToken(TokenizeParser.PUBLIC, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_public

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPublic" ):
                listener.enterPublic(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPublic" ):
                listener.exitPublic(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitPublic" ):
                return visitor.visitPublic(self)
            else:
                return visitor.visitChildren(self)




    def public(self):

        localctx = TokenizeParser.PublicContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_public)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 117
            self.match(TokenizeParser.PUBLIC)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class PrivateContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def PRIVATE(self):
            return self.getToken(TokenizeParser.PRIVATE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_private

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPrivate" ):
                listener.enterPrivate(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPrivate" ):
                listener.exitPrivate(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitPrivate" ):
                return visitor.visitPrivate(self)
            else:
                return visitor.visitChildren(self)




    def private(self):

        localctx = TokenizeParser.PrivateContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_private)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 119
            self.match(TokenizeParser.PRIVATE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class InternalContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INTERNAL(self):
            return self.getToken(TokenizeParser.INTERNAL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_internal

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInternal" ):
                listener.enterInternal(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInternal" ):
                listener.exitInternal(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInternal" ):
                return visitor.visitInternal(self)
            else:
                return visitor.visitChildren(self)




    def internal(self):

        localctx = TokenizeParser.InternalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_internal)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 121
            self.match(TokenizeParser.INTERNAL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class MutableContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MUTABLE(self):
            return self.getToken(TokenizeParser.MUTABLE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_mutable

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMutable" ):
                listener.enterMutable(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMutable" ):
                listener.exitMutable(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMutable" ):
                return visitor.visitMutable(self)
            else:
                return visitor.visitChildren(self)




    def mutable(self):

        localctx = TokenizeParser.MutableContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_mutable)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 123
            self.match(TokenizeParser.MUTABLE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class LetContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LET(self):
            return self.getToken(TokenizeParser.LET, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_let

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLet" ):
                listener.enterLet(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLet" ):
                listener.exitLet(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLet" ):
                return visitor.visitLet(self)
            else:
                return visitor.visitChildren(self)




    def let(self):

        localctx = TokenizeParser.LetContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_let)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 125
            self.match(TokenizeParser.LET)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class FunContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def FUN(self):
            return self.getToken(TokenizeParser.FUN, 0)

        def RIGHT_ARROW(self):
            return self.getToken(TokenizeParser.RIGHT_ARROW, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_fun

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFun" ):
                listener.enterFun(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFun" ):
                listener.exitFun(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitFun" ):
                return visitor.visitFun(self)
            else:
                return visitor.visitChildren(self)




    def fun(self):

        localctx = TokenizeParser.FunContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_fun)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 127
            self.match(TokenizeParser.FUN)
            self.state = 129 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 128
                self.expression()
                self.state = 131 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & 17170464) != 0)):
                    break

            self.state = 133
            self.match(TokenizeParser.RIGHT_ARROW)
            self.state = 134
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class TypezationContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def COLON(self):
            return self.getToken(TokenizeParser.COLON, 0)

        def round_brackets(self):
            return self.getTypedRuleContext(TokenizeParser.Round_bracketsContext,0)


        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_typezation

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterTypezation" ):
                listener.enterTypezation(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitTypezation" ):
                listener.exitTypezation(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitTypezation" ):
                return visitor.visitTypezation(self)
            else:
                return visitor.visitChildren(self)




    def typezation(self):

        localctx = TokenizeParser.TypezationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_typezation)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 136
            self.match(TokenizeParser.COLON)
            self.state = 139
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [9]:
                self.state = 137
                self.round_brackets()
                pass
            elif token in [17]:
                self.state = 138
                self.dotIentifier()
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class If_then_elif_elseContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_if_then_elif_else

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterIf_then_elif_else" ):
                listener.enterIf_then_elif_else(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitIf_then_elif_else" ):
                listener.exitIf_then_elif_else(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitIf_then_elif_else" ):
                return visitor.visitIf_then_elif_else(self)
            else:
                return visitor.visitChildren(self)




    def if_then_elif_else(self):

        localctx = TokenizeParser.If_then_elif_elseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_if_then_elif_else)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 141
            self.match(TokenizeParser.T__10)
            self.state = 143 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 142
                self.expression()
                self.state = 145 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & 17170464) != 0)):
                    break

            self.state = 147
            self.match(TokenizeParser.T__11)
            self.state = 149 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 148
                self.expression()
                self.state = 151 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & 17170464) != 0)):
                    break

            self.state = 167
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==13:
                self.state = 153
                self.match(TokenizeParser.T__12)
                self.state = 155 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while True:
                    self.state = 154
                    self.expression()
                    self.state = 157 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & 17170464) != 0)):
                        break

                self.state = 159
                self.match(TokenizeParser.T__11)
                self.state = 161 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while True:
                    self.state = 160
                    self.expression()
                    self.state = 163 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & 17170464) != 0)):
                        break

                self.state = 169
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 172
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==14:
                self.state = 170
                self.match(TokenizeParser.T__13)
                self.state = 171
                self.expression()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AddContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def ADD(self):
            return self.getToken(TokenizeParser.ADD, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_add

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAdd" ):
                listener.enterAdd(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAdd" ):
                listener.exitAdd(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitAdd" ):
                return visitor.visitAdd(self)
            else:
                return visitor.visitChildren(self)




    def add(self):

        localctx = TokenizeParser.AddContext(self, self._ctx, self.state)
        self.enterRule(localctx, 42, self.RULE_add)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 174
            self.match(TokenizeParser.ADD)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class MulContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MUL(self):
            return self.getToken(TokenizeParser.MUL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_mul

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMul" ):
                listener.enterMul(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMul" ):
                listener.exitMul(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMul" ):
                return visitor.visitMul(self)
            else:
                return visitor.visitChildren(self)




    def mul(self):

        localctx = TokenizeParser.MulContext(self, self._ctx, self.state)
        self.enterRule(localctx, 44, self.RULE_mul)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 176
            self.match(TokenizeParser.MUL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class DivContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def DIV(self):
            return self.getToken(TokenizeParser.DIV, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_div

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDiv" ):
                listener.enterDiv(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDiv" ):
                listener.exitDiv(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDiv" ):
                return visitor.visitDiv(self)
            else:
                return visitor.visitChildren(self)




    def div(self):

        localctx = TokenizeParser.DivContext(self, self._ctx, self.state)
        self.enterRule(localctx, 46, self.RULE_div)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 178
            self.match(TokenizeParser.DIV)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class MinusContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MINUS(self):
            return self.getToken(TokenizeParser.MINUS, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_minus

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMinus" ):
                listener.enterMinus(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMinus" ):
                listener.exitMinus(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMinus" ):
                return visitor.visitMinus(self)
            else:
                return visitor.visitChildren(self)




    def minus(self):

        localctx = TokenizeParser.MinusContext(self, self._ctx, self.state)
        self.enterRule(localctx, 48, self.RULE_minus)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 180
            self.match(TokenizeParser.MINUS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class PowContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def POW(self):
            return self.getToken(TokenizeParser.POW, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_pow

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPow" ):
                listener.enterPow(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPow" ):
                listener.exitPow(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitPow" ):
                return visitor.visitPow(self)
            else:
                return visitor.visitChildren(self)




    def pow_(self):

        localctx = TokenizeParser.PowContext(self, self._ctx, self.state)
        self.enterRule(localctx, 50, self.RULE_pow)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 182
            self.match(TokenizeParser.POW)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ModContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MOD(self):
            return self.getToken(TokenizeParser.MOD, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_mod

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMod" ):
                listener.enterMod(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMod" ):
                listener.exitMod(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMod" ):
                return visitor.visitMod(self)
            else:
                return visitor.visitChildren(self)




    def mod(self):

        localctx = TokenizeParser.ModContext(self, self._ctx, self.state)
        self.enterRule(localctx, 52, self.RULE_mod)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 184
            self.match(TokenizeParser.MOD)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class EqualContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def EQUAL(self):
            return self.getToken(TokenizeParser.EQUAL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_equal

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEqual" ):
                listener.enterEqual(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEqual" ):
                listener.exitEqual(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitEqual" ):
                return visitor.visitEqual(self)
            else:
                return visitor.visitChildren(self)




    def equal(self):

        localctx = TokenizeParser.EqualContext(self, self._ctx, self.state)
        self.enterRule(localctx, 54, self.RULE_equal)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 186
            self.match(TokenizeParser.EQUAL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ExpressionContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def int_(self):
            return self.getTypedRuleContext(TokenizeParser.IntContext,0)


        def unit(self):
            return self.getTypedRuleContext(TokenizeParser.UnitContext,0)


        def attribute(self):
            return self.getTypedRuleContext(TokenizeParser.AttributeContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_expression

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExpression" ):
                listener.enterExpression(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExpression" ):
                listener.exitExpression(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitExpression" ):
                return visitor.visitExpression(self)
            else:
                return visitor.visitChildren(self)




    def expression(self):

        localctx = TokenizeParser.ExpressionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 56, self.RULE_expression)
        try:
            self.state = 192
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [17]:
                self.enterOuterAlt(localctx, 1)
                self.state = 188
                self.dotIentifier()
                pass
            elif token in [18]:
                self.enterOuterAlt(localctx, 2)
                self.state = 189
                self.int_()
                pass
            elif token in [24]:
                self.enterOuterAlt(localctx, 3)
                self.state = 190
                self.unit()
                pass
            elif token in [5]:
                self.enterOuterAlt(localctx, 4)
                self.state = 191
                self.attribute()
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ExprsContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def EOF(self):
            return self.getToken(TokenizeParser.EOF, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_exprs

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExprs" ):
                listener.enterExprs(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExprs" ):
                listener.exitExprs(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitExprs" ):
                return visitor.visitExprs(self)
            else:
                return visitor.visitChildren(self)




    def exprs(self):

        localctx = TokenizeParser.ExprsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 58, self.RULE_exprs)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 197
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & 17170464) != 0):
                self.state = 194
                self.expression()
                self.state = 199
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 200
            self.match(TokenizeParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





