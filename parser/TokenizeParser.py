# Generated from Tokenize.g4 by ANTLR 4.13.1
# encoding: utf-8
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
	from typing import TextIO
else:
	from typing.io import TextIO

def serializedATN():
    return [
        4,1,108,867,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,
        7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,
        13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,
        20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,
        26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,32,2,
        33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,39,7,
        39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,7,45,2,
        46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,2,52,7,
        52,2,53,7,53,2,54,7,54,2,55,7,55,2,56,7,56,2,57,7,57,2,58,7,58,2,
        59,7,59,2,60,7,60,2,61,7,61,2,62,7,62,2,63,7,63,2,64,7,64,2,65,7,
        65,2,66,7,66,2,67,7,67,2,68,7,68,2,69,7,69,2,70,7,70,2,71,7,71,2,
        72,7,72,2,73,7,73,2,74,7,74,2,75,7,75,2,76,7,76,2,77,7,77,2,78,7,
        78,2,79,7,79,2,80,7,80,2,81,7,81,2,82,7,82,2,83,7,83,2,84,7,84,2,
        85,7,85,2,86,7,86,2,87,7,87,2,88,7,88,2,89,7,89,2,90,7,90,2,91,7,
        91,2,92,7,92,1,0,1,0,1,1,1,1,1,1,1,1,5,1,193,8,1,10,1,12,1,196,9,
        1,1,2,1,2,1,3,1,3,1,4,1,4,1,5,1,5,1,6,1,6,1,7,1,7,1,8,1,8,1,9,1,
        9,1,10,3,10,215,8,10,1,10,1,10,1,10,1,10,1,10,1,10,1,10,5,10,224,
        8,10,10,10,12,10,227,9,10,1,10,1,10,1,11,1,11,1,11,1,11,1,11,1,11,
        1,12,1,12,4,12,239,8,12,11,12,12,12,240,1,12,1,12,1,13,1,13,1,14,
        1,14,1,15,1,15,1,16,1,16,1,17,1,17,1,18,1,18,1,19,1,19,4,19,259,
        8,19,11,19,12,19,260,1,19,1,19,1,19,1,20,1,20,1,20,4,20,269,8,20,
        11,20,12,20,270,1,21,1,21,1,21,3,21,276,8,21,1,22,1,22,4,22,280,
        8,22,11,22,12,22,281,1,22,1,22,4,22,286,8,22,11,22,12,22,287,1,22,
        1,22,4,22,292,8,22,11,22,12,22,293,1,22,1,22,4,22,298,8,22,11,22,
        12,22,299,5,22,302,8,22,10,22,12,22,305,9,22,1,22,1,22,3,22,309,
        8,22,1,23,1,23,4,23,313,8,23,11,23,12,23,314,1,23,1,23,1,24,1,24,
        4,24,321,8,24,11,24,12,24,322,1,24,1,24,4,24,327,8,24,11,24,12,24,
        328,1,24,1,24,1,25,1,25,1,26,1,26,1,27,1,27,1,28,1,28,1,29,1,29,
        1,30,1,30,1,31,1,31,1,32,1,32,1,33,1,33,1,34,1,34,1,35,1,35,1,36,
        1,36,1,37,1,37,1,38,1,38,1,39,1,39,1,40,1,40,1,41,1,41,1,42,1,42,
        1,43,1,43,1,44,1,44,1,45,1,45,1,46,1,46,1,47,1,47,1,48,1,48,1,49,
        1,49,4,49,383,8,49,11,49,12,49,384,1,49,1,49,1,49,1,50,1,50,1,50,
        1,51,1,51,1,51,1,52,1,52,1,52,1,53,1,53,4,53,401,8,53,11,53,12,53,
        402,1,53,1,53,1,54,1,54,1,55,1,55,1,55,1,56,1,56,1,57,1,57,1,57,
        4,57,417,8,57,11,57,12,57,418,1,57,1,57,4,57,423,8,57,11,57,12,57,
        424,5,57,427,8,57,10,57,12,57,430,9,57,1,57,1,57,1,58,1,58,4,58,
        436,8,58,11,58,12,58,437,1,58,1,58,4,58,442,8,58,11,58,12,58,443,
        5,58,446,8,58,10,58,12,58,449,9,58,1,58,1,58,1,59,1,59,4,59,455,
        8,59,11,59,12,59,456,1,59,1,59,4,59,461,8,59,11,59,12,59,462,5,59,
        465,8,59,10,59,12,59,468,9,59,1,59,1,59,1,60,1,60,1,60,4,60,475,
        8,60,11,60,12,60,476,1,60,1,60,4,60,481,8,60,11,60,12,60,482,1,60,
        1,60,4,60,487,8,60,11,60,12,60,488,1,60,1,60,4,60,493,8,60,11,60,
        12,60,494,5,60,497,8,60,10,60,12,60,500,9,60,1,60,1,60,1,61,1,61,
        1,61,1,61,1,61,3,61,509,8,61,1,62,1,62,1,62,1,63,1,63,1,63,5,63,
        517,8,63,10,63,12,63,520,9,63,1,63,1,63,1,64,1,64,1,64,5,64,527,
        8,64,10,64,12,64,530,9,64,1,64,1,64,1,65,1,65,1,66,1,66,4,66,538,
        8,66,11,66,12,66,539,1,66,1,66,1,66,4,66,545,8,66,11,66,12,66,546,
        1,66,1,66,4,66,551,8,66,11,66,12,66,552,1,66,1,66,4,66,557,8,66,
        11,66,12,66,558,1,67,1,67,5,67,563,8,67,10,67,12,67,566,9,67,1,67,
        1,67,1,67,5,67,571,8,67,10,67,12,67,574,9,67,1,67,1,67,5,67,578,
        8,67,10,67,12,67,581,9,67,5,67,583,8,67,10,67,12,67,586,9,67,3,67,
        588,8,67,1,67,1,67,3,67,592,8,67,1,68,1,68,5,68,596,8,68,10,68,12,
        68,599,9,68,1,68,1,68,1,68,1,69,1,69,1,69,1,69,1,70,1,70,1,71,1,
        71,1,72,1,72,1,73,1,73,1,74,1,74,5,74,618,8,74,10,74,12,74,621,9,
        74,1,74,1,74,1,74,1,75,1,75,1,75,1,75,4,75,630,8,75,11,75,12,75,
        631,1,75,1,75,1,75,1,76,1,76,3,76,639,8,76,1,76,1,76,1,76,3,76,644,
        8,76,1,76,1,76,1,76,1,76,1,77,1,77,5,77,652,8,77,10,77,12,77,655,
        9,77,1,77,1,77,1,78,1,78,1,78,1,78,3,78,663,8,78,1,78,1,78,1,78,
        1,78,1,78,1,78,1,78,1,78,1,78,3,78,674,8,78,1,78,1,78,5,78,678,8,
        78,10,78,12,78,681,9,78,1,78,1,78,3,78,685,8,78,1,78,1,78,1,78,1,
        78,3,78,691,8,78,1,78,5,78,694,8,78,10,78,12,78,697,9,78,1,78,1,
        78,3,78,701,8,78,1,79,1,79,1,79,1,79,4,79,707,8,79,11,79,12,79,708,
        1,79,1,79,1,80,1,80,1,81,1,81,1,81,1,81,1,81,5,81,720,8,81,10,81,
        12,81,723,9,81,1,81,5,81,726,8,81,10,81,12,81,729,9,81,1,81,1,81,
        5,81,733,8,81,10,81,12,81,736,9,81,3,81,738,8,81,1,81,1,81,1,82,
        1,82,1,83,1,83,1,83,1,83,3,83,748,8,83,1,83,1,83,4,83,752,8,83,11,
        83,12,83,753,1,84,1,84,1,85,1,85,1,86,1,86,1,87,1,87,1,88,1,88,1,
        89,1,89,1,90,1,90,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,
        91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,
        91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,
        91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,
        91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,
        91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,
        91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,1,91,3,
        91,857,8,91,1,92,5,92,860,8,92,10,92,12,92,863,9,92,1,92,1,92,1,
        92,0,0,93,0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,
        40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,
        84,86,88,90,92,94,96,98,100,102,104,106,108,110,112,114,116,118,
        120,122,124,126,128,130,132,134,136,138,140,142,144,146,148,150,
        152,154,156,158,160,162,164,166,168,170,172,174,176,178,180,182,
        184,0,3,1,0,35,37,1,0,18,19,2,0,58,58,84,84,935,0,186,1,0,0,0,2,
        188,1,0,0,0,4,197,1,0,0,0,6,199,1,0,0,0,8,201,1,0,0,0,10,203,1,0,
        0,0,12,205,1,0,0,0,14,207,1,0,0,0,16,209,1,0,0,0,18,211,1,0,0,0,
        20,214,1,0,0,0,22,230,1,0,0,0,24,236,1,0,0,0,26,244,1,0,0,0,28,246,
        1,0,0,0,30,248,1,0,0,0,32,250,1,0,0,0,34,252,1,0,0,0,36,254,1,0,
        0,0,38,256,1,0,0,0,40,265,1,0,0,0,42,272,1,0,0,0,44,277,1,0,0,0,
        46,310,1,0,0,0,48,318,1,0,0,0,50,332,1,0,0,0,52,334,1,0,0,0,54,336,
        1,0,0,0,56,338,1,0,0,0,58,340,1,0,0,0,60,342,1,0,0,0,62,344,1,0,
        0,0,64,346,1,0,0,0,66,348,1,0,0,0,68,350,1,0,0,0,70,352,1,0,0,0,
        72,354,1,0,0,0,74,356,1,0,0,0,76,358,1,0,0,0,78,360,1,0,0,0,80,362,
        1,0,0,0,82,364,1,0,0,0,84,366,1,0,0,0,86,368,1,0,0,0,88,370,1,0,
        0,0,90,372,1,0,0,0,92,374,1,0,0,0,94,376,1,0,0,0,96,378,1,0,0,0,
        98,380,1,0,0,0,100,389,1,0,0,0,102,392,1,0,0,0,104,395,1,0,0,0,106,
        398,1,0,0,0,108,406,1,0,0,0,110,408,1,0,0,0,112,411,1,0,0,0,114,
        413,1,0,0,0,116,433,1,0,0,0,118,452,1,0,0,0,120,471,1,0,0,0,122,
        503,1,0,0,0,124,510,1,0,0,0,126,513,1,0,0,0,128,523,1,0,0,0,130,
        533,1,0,0,0,132,535,1,0,0,0,134,560,1,0,0,0,136,593,1,0,0,0,138,
        603,1,0,0,0,140,607,1,0,0,0,142,609,1,0,0,0,144,611,1,0,0,0,146,
        613,1,0,0,0,148,615,1,0,0,0,150,625,1,0,0,0,152,636,1,0,0,0,154,
        649,1,0,0,0,156,700,1,0,0,0,158,702,1,0,0,0,160,712,1,0,0,0,162,
        714,1,0,0,0,164,741,1,0,0,0,166,751,1,0,0,0,168,755,1,0,0,0,170,
        757,1,0,0,0,172,759,1,0,0,0,174,761,1,0,0,0,176,763,1,0,0,0,178,
        765,1,0,0,0,180,767,1,0,0,0,182,856,1,0,0,0,184,861,1,0,0,0,186,
        187,5,76,0,0,187,1,1,0,0,0,188,194,5,17,0,0,189,190,3,0,0,0,190,
        191,5,17,0,0,191,193,1,0,0,0,192,189,1,0,0,0,193,196,1,0,0,0,194,
        192,1,0,0,0,194,195,1,0,0,0,195,3,1,0,0,0,196,194,1,0,0,0,197,198,
        5,18,0,0,198,5,1,0,0,0,199,200,5,19,0,0,200,7,1,0,0,0,201,202,5,
        24,0,0,202,9,1,0,0,0,203,204,5,23,0,0,204,11,1,0,0,0,205,206,5,21,
        0,0,206,13,1,0,0,0,207,208,5,84,0,0,208,15,1,0,0,0,209,210,5,20,
        0,0,210,17,1,0,0,0,211,212,5,38,0,0,212,19,1,0,0,0,213,215,3,18,
        9,0,214,213,1,0,0,0,214,215,1,0,0,0,215,216,1,0,0,0,216,225,5,1,
        0,0,217,218,5,2,0,0,218,219,3,182,91,0,219,220,5,3,0,0,220,224,1,
        0,0,0,221,224,3,16,8,0,222,224,5,21,0,0,223,217,1,0,0,0,223,221,
        1,0,0,0,223,222,1,0,0,0,224,227,1,0,0,0,225,223,1,0,0,0,225,226,
        1,0,0,0,226,228,1,0,0,0,227,225,1,0,0,0,228,229,5,1,0,0,229,21,1,
        0,0,0,230,231,5,4,0,0,231,232,5,95,0,0,232,233,3,2,1,0,233,234,5,
        96,0,0,234,235,5,5,0,0,235,23,1,0,0,0,236,238,5,6,0,0,237,239,3,
        182,91,0,238,237,1,0,0,0,239,240,1,0,0,0,240,238,1,0,0,0,240,241,
        1,0,0,0,241,242,1,0,0,0,242,243,5,7,0,0,243,25,1,0,0,0,244,245,5,
        25,0,0,245,27,1,0,0,0,246,247,5,26,0,0,247,29,1,0,0,0,248,249,5,
        27,0,0,249,31,1,0,0,0,250,251,5,28,0,0,251,33,1,0,0,0,252,253,5,
        29,0,0,253,35,1,0,0,0,254,255,5,30,0,0,255,37,1,0,0,0,256,258,5,
        31,0,0,257,259,3,182,91,0,258,257,1,0,0,0,259,260,1,0,0,0,260,258,
        1,0,0,0,260,261,1,0,0,0,261,262,1,0,0,0,262,263,5,85,0,0,263,264,
        3,182,91,0,264,39,1,0,0,0,265,268,3,2,1,0,266,267,5,85,0,0,267,269,
        3,2,1,0,268,266,1,0,0,0,269,270,1,0,0,0,270,268,1,0,0,0,270,271,
        1,0,0,0,271,41,1,0,0,0,272,275,5,81,0,0,273,276,3,24,12,0,274,276,
        3,2,1,0,275,273,1,0,0,0,275,274,1,0,0,0,276,43,1,0,0,0,277,279,5,
        8,0,0,278,280,3,182,91,0,279,278,1,0,0,0,280,281,1,0,0,0,281,279,
        1,0,0,0,281,282,1,0,0,0,282,283,1,0,0,0,283,285,5,57,0,0,284,286,
        3,182,91,0,285,284,1,0,0,0,286,287,1,0,0,0,287,285,1,0,0,0,287,288,
        1,0,0,0,288,303,1,0,0,0,289,291,5,9,0,0,290,292,3,182,91,0,291,290,
        1,0,0,0,292,293,1,0,0,0,293,291,1,0,0,0,293,294,1,0,0,0,294,295,
        1,0,0,0,295,297,5,57,0,0,296,298,3,182,91,0,297,296,1,0,0,0,298,
        299,1,0,0,0,299,297,1,0,0,0,299,300,1,0,0,0,300,302,1,0,0,0,301,
        289,1,0,0,0,302,305,1,0,0,0,303,301,1,0,0,0,303,304,1,0,0,0,304,
        308,1,0,0,0,305,303,1,0,0,0,306,307,5,10,0,0,307,309,3,182,91,0,
        308,306,1,0,0,0,308,309,1,0,0,0,309,45,1,0,0,0,310,312,5,32,0,0,
        311,313,3,182,91,0,312,311,1,0,0,0,313,314,1,0,0,0,314,312,1,0,0,
        0,314,315,1,0,0,0,315,316,1,0,0,0,316,317,5,33,0,0,317,47,1,0,0,
        0,318,320,5,34,0,0,319,321,3,182,91,0,320,319,1,0,0,0,321,322,1,
        0,0,0,322,320,1,0,0,0,322,323,1,0,0,0,323,324,1,0,0,0,324,326,7,
        0,0,0,325,327,3,182,91,0,326,325,1,0,0,0,327,328,1,0,0,0,328,326,
        1,0,0,0,328,329,1,0,0,0,329,330,1,0,0,0,330,331,5,33,0,0,331,49,
        1,0,0,0,332,333,5,87,0,0,333,51,1,0,0,0,334,335,5,89,0,0,335,53,
        1,0,0,0,336,337,5,90,0,0,337,55,1,0,0,0,338,339,5,88,0,0,339,57,
        1,0,0,0,340,341,5,91,0,0,341,59,1,0,0,0,342,343,5,92,0,0,343,61,
        1,0,0,0,344,345,5,94,0,0,345,63,1,0,0,0,346,347,5,95,0,0,347,65,
        1,0,0,0,348,349,5,97,0,0,349,67,1,0,0,0,350,351,5,96,0,0,351,69,
        1,0,0,0,352,353,5,98,0,0,353,71,1,0,0,0,354,355,5,93,0,0,355,73,
        1,0,0,0,356,357,5,99,0,0,357,75,1,0,0,0,358,359,5,100,0,0,359,77,
        1,0,0,0,360,361,5,101,0,0,361,79,1,0,0,0,362,363,5,102,0,0,363,81,
        1,0,0,0,364,365,5,103,0,0,365,83,1,0,0,0,366,367,5,104,0,0,367,85,
        1,0,0,0,368,369,5,105,0,0,369,87,1,0,0,0,370,371,5,106,0,0,371,89,
        1,0,0,0,372,373,5,107,0,0,373,91,1,0,0,0,374,375,5,83,0,0,375,93,
        1,0,0,0,376,377,5,86,0,0,377,95,1,0,0,0,378,379,5,82,0,0,379,97,
        1,0,0,0,380,382,5,39,0,0,381,383,3,182,91,0,382,381,1,0,0,0,383,
        384,1,0,0,0,384,382,1,0,0,0,384,385,1,0,0,0,385,386,1,0,0,0,386,
        387,5,93,0,0,387,388,3,182,91,0,388,99,1,0,0,0,389,390,5,40,0,0,
        390,391,3,2,1,0,391,101,1,0,0,0,392,393,5,41,0,0,393,394,3,2,1,0,
        394,103,1,0,0,0,395,396,5,42,0,0,396,397,3,2,1,0,397,105,1,0,0,0,
        398,400,5,43,0,0,399,401,3,182,91,0,400,399,1,0,0,0,401,402,1,0,
        0,0,402,400,1,0,0,0,402,403,1,0,0,0,403,404,1,0,0,0,404,405,5,44,
        0,0,405,107,1,0,0,0,406,407,5,33,0,0,407,109,1,0,0,0,408,409,5,56,
        0,0,409,410,3,182,91,0,410,111,1,0,0,0,411,412,5,57,0,0,412,113,
        1,0,0,0,413,414,5,60,0,0,414,416,5,2,0,0,415,417,3,182,91,0,416,
        415,1,0,0,0,417,418,1,0,0,0,418,416,1,0,0,0,418,419,1,0,0,0,419,
        428,1,0,0,0,420,422,5,80,0,0,421,423,3,182,91,0,422,421,1,0,0,0,
        423,424,1,0,0,0,424,422,1,0,0,0,424,425,1,0,0,0,425,427,1,0,0,0,
        426,420,1,0,0,0,427,430,1,0,0,0,428,426,1,0,0,0,428,429,1,0,0,0,
        429,431,1,0,0,0,430,428,1,0,0,0,431,432,5,3,0,0,432,115,1,0,0,0,
        433,435,5,4,0,0,434,436,3,182,91,0,435,434,1,0,0,0,436,437,1,0,0,
        0,437,435,1,0,0,0,437,438,1,0,0,0,438,447,1,0,0,0,439,441,5,80,0,
        0,440,442,3,182,91,0,441,440,1,0,0,0,442,443,1,0,0,0,443,441,1,0,
        0,0,443,444,1,0,0,0,444,446,1,0,0,0,445,439,1,0,0,0,446,449,1,0,
        0,0,447,445,1,0,0,0,447,448,1,0,0,0,448,450,1,0,0,0,449,447,1,0,
        0,0,450,451,5,5,0,0,451,117,1,0,0,0,452,454,5,11,0,0,453,455,3,182,
        91,0,454,453,1,0,0,0,455,456,1,0,0,0,456,454,1,0,0,0,456,457,1,0,
        0,0,457,466,1,0,0,0,458,460,5,80,0,0,459,461,3,182,91,0,460,459,
        1,0,0,0,461,462,1,0,0,0,462,460,1,0,0,0,462,463,1,0,0,0,463,465,
        1,0,0,0,464,458,1,0,0,0,465,468,1,0,0,0,466,464,1,0,0,0,466,467,
        1,0,0,0,467,469,1,0,0,0,468,466,1,0,0,0,469,470,5,12,0,0,470,119,
        1,0,0,0,471,472,5,61,0,0,472,474,5,4,0,0,473,475,3,182,91,0,474,
        473,1,0,0,0,475,476,1,0,0,0,476,474,1,0,0,0,476,477,1,0,0,0,477,
        478,1,0,0,0,478,480,5,79,0,0,479,481,3,182,91,0,480,479,1,0,0,0,
        481,482,1,0,0,0,482,480,1,0,0,0,482,483,1,0,0,0,483,498,1,0,0,0,
        484,486,5,80,0,0,485,487,3,182,91,0,486,485,1,0,0,0,487,488,1,0,
        0,0,488,486,1,0,0,0,488,489,1,0,0,0,489,490,1,0,0,0,490,492,5,79,
        0,0,491,493,3,182,91,0,492,491,1,0,0,0,493,494,1,0,0,0,494,492,1,
        0,0,0,494,495,1,0,0,0,495,497,1,0,0,0,496,484,1,0,0,0,497,500,1,
        0,0,0,498,496,1,0,0,0,498,499,1,0,0,0,499,501,1,0,0,0,500,498,1,
        0,0,0,501,502,5,5,0,0,502,121,1,0,0,0,503,504,7,1,0,0,504,505,5,
        77,0,0,505,508,7,1,0,0,506,507,5,77,0,0,507,509,7,1,0,0,508,506,
        1,0,0,0,508,509,1,0,0,0,509,123,1,0,0,0,510,511,5,62,0,0,511,512,
        3,182,91,0,512,125,1,0,0,0,513,514,5,54,0,0,514,518,5,2,0,0,515,
        517,3,182,91,0,516,515,1,0,0,0,517,520,1,0,0,0,518,516,1,0,0,0,518,
        519,1,0,0,0,519,521,1,0,0,0,520,518,1,0,0,0,521,522,5,3,0,0,522,
        127,1,0,0,0,523,524,5,55,0,0,524,528,5,2,0,0,525,527,3,182,91,0,
        526,525,1,0,0,0,527,530,1,0,0,0,528,526,1,0,0,0,528,529,1,0,0,0,
        529,531,1,0,0,0,530,528,1,0,0,0,531,532,5,3,0,0,532,129,1,0,0,0,
        533,534,5,78,0,0,534,131,1,0,0,0,535,537,5,70,0,0,536,538,3,182,
        91,0,537,536,1,0,0,0,538,539,1,0,0,0,539,537,1,0,0,0,539,540,1,0,
        0,0,540,541,1,0,0,0,541,556,5,71,0,0,542,544,5,13,0,0,543,545,3,
        182,91,0,544,543,1,0,0,0,545,546,1,0,0,0,546,544,1,0,0,0,546,547,
        1,0,0,0,547,548,1,0,0,0,548,550,5,85,0,0,549,551,3,182,91,0,550,
        549,1,0,0,0,551,552,1,0,0,0,552,550,1,0,0,0,552,553,1,0,0,0,553,
        554,1,0,0,0,554,555,5,14,0,0,555,557,1,0,0,0,556,542,1,0,0,0,557,
        558,1,0,0,0,558,556,1,0,0,0,558,559,1,0,0,0,559,133,1,0,0,0,560,
        564,5,68,0,0,561,563,3,182,91,0,562,561,1,0,0,0,563,566,1,0,0,0,
        564,562,1,0,0,0,564,565,1,0,0,0,565,587,1,0,0,0,566,564,1,0,0,0,
        567,584,5,71,0,0,568,572,5,13,0,0,569,571,3,182,91,0,570,569,1,0,
        0,0,571,574,1,0,0,0,572,570,1,0,0,0,572,573,1,0,0,0,573,575,1,0,
        0,0,574,572,1,0,0,0,575,579,5,85,0,0,576,578,3,182,91,0,577,576,
        1,0,0,0,578,581,1,0,0,0,579,577,1,0,0,0,579,580,1,0,0,0,580,583,
        1,0,0,0,581,579,1,0,0,0,582,568,1,0,0,0,583,586,1,0,0,0,584,582,
        1,0,0,0,584,585,1,0,0,0,585,588,1,0,0,0,586,584,1,0,0,0,587,567,
        1,0,0,0,587,588,1,0,0,0,588,591,1,0,0,0,589,590,5,69,0,0,590,592,
        3,182,91,0,591,589,1,0,0,0,591,592,1,0,0,0,592,135,1,0,0,0,593,597,
        5,72,0,0,594,596,3,182,91,0,595,594,1,0,0,0,596,599,1,0,0,0,597,
        595,1,0,0,0,597,598,1,0,0,0,598,600,1,0,0,0,599,597,1,0,0,0,600,
        601,5,93,0,0,601,602,3,182,91,0,602,137,1,0,0,0,603,604,5,73,0,0,
        604,605,3,24,12,0,605,606,3,182,91,0,606,139,1,0,0,0,607,608,5,63,
        0,0,608,141,1,0,0,0,609,610,5,64,0,0,610,143,1,0,0,0,611,612,5,65,
        0,0,612,145,1,0,0,0,613,614,5,66,0,0,614,147,1,0,0,0,615,619,5,74,
        0,0,616,618,3,182,91,0,617,616,1,0,0,0,618,621,1,0,0,0,619,617,1,
        0,0,0,619,620,1,0,0,0,620,622,1,0,0,0,621,619,1,0,0,0,622,623,5,
        75,0,0,623,624,3,182,91,0,624,149,1,0,0,0,625,626,5,59,0,0,626,627,
        7,2,0,0,627,629,3,0,0,0,628,630,3,2,1,0,629,628,1,0,0,0,630,631,
        1,0,0,0,631,629,1,0,0,0,631,632,1,0,0,0,632,633,1,0,0,0,633,634,
        3,72,36,0,634,635,3,182,91,0,635,151,1,0,0,0,636,638,5,67,0,0,637,
        639,3,34,17,0,638,637,1,0,0,0,638,639,1,0,0,0,639,643,1,0,0,0,640,
        644,3,32,16,0,641,644,3,28,14,0,642,644,3,30,15,0,643,640,1,0,0,
        0,643,641,1,0,0,0,643,642,1,0,0,0,643,644,1,0,0,0,644,645,1,0,0,
        0,645,646,3,2,1,0,646,647,5,81,0,0,647,648,3,2,1,0,648,153,1,0,0,
        0,649,653,5,45,0,0,650,652,3,182,91,0,651,650,1,0,0,0,652,655,1,
        0,0,0,653,651,1,0,0,0,653,654,1,0,0,0,654,656,1,0,0,0,655,653,1,
        0,0,0,656,657,5,44,0,0,657,155,1,0,0,0,658,662,5,71,0,0,659,663,
        3,30,15,0,660,663,3,32,16,0,661,663,3,28,14,0,662,659,1,0,0,0,662,
        660,1,0,0,0,662,661,1,0,0,0,662,663,1,0,0,0,663,664,1,0,0,0,664,
        665,5,48,0,0,665,666,5,24,0,0,666,667,5,93,0,0,667,668,3,182,91,
        0,668,669,1,0,0,0,669,684,5,99,0,0,670,674,3,30,15,0,671,674,3,32,
        16,0,672,674,3,28,14,0,673,670,1,0,0,0,673,671,1,0,0,0,673,672,1,
        0,0,0,673,674,1,0,0,0,674,675,1,0,0,0,675,679,5,62,0,0,676,678,3,
        182,91,0,677,676,1,0,0,0,678,681,1,0,0,0,679,677,1,0,0,0,679,680,
        1,0,0,0,680,682,1,0,0,0,681,679,1,0,0,0,682,683,5,93,0,0,683,685,
        3,182,91,0,684,673,1,0,0,0,684,685,1,0,0,0,685,701,1,0,0,0,686,690,
        5,71,0,0,687,691,3,30,15,0,688,691,3,32,16,0,689,691,3,28,14,0,690,
        687,1,0,0,0,690,688,1,0,0,0,690,689,1,0,0,0,690,691,1,0,0,0,691,
        695,1,0,0,0,692,694,3,182,91,0,693,692,1,0,0,0,694,697,1,0,0,0,695,
        693,1,0,0,0,695,696,1,0,0,0,696,698,1,0,0,0,697,695,1,0,0,0,698,
        699,5,93,0,0,699,701,3,182,91,0,700,658,1,0,0,0,700,686,1,0,0,0,
        701,157,1,0,0,0,702,703,5,6,0,0,703,706,3,182,91,0,704,705,5,79,
        0,0,705,707,3,182,91,0,706,704,1,0,0,0,707,708,1,0,0,0,708,706,1,
        0,0,0,708,709,1,0,0,0,709,710,1,0,0,0,710,711,5,7,0,0,711,159,1,
        0,0,0,712,713,5,71,0,0,713,161,1,0,0,0,714,737,5,2,0,0,715,716,3,
        182,91,0,716,717,5,81,0,0,717,718,3,2,1,0,718,720,1,0,0,0,719,715,
        1,0,0,0,720,723,1,0,0,0,721,719,1,0,0,0,721,722,1,0,0,0,722,738,
        1,0,0,0,723,721,1,0,0,0,724,726,3,182,91,0,725,724,1,0,0,0,726,729,
        1,0,0,0,727,725,1,0,0,0,727,728,1,0,0,0,728,730,1,0,0,0,729,727,
        1,0,0,0,730,734,3,160,80,0,731,733,3,182,91,0,732,731,1,0,0,0,733,
        736,1,0,0,0,734,732,1,0,0,0,734,735,1,0,0,0,735,738,1,0,0,0,736,
        734,1,0,0,0,737,721,1,0,0,0,737,727,1,0,0,0,738,739,1,0,0,0,739,
        740,5,3,0,0,740,163,1,0,0,0,741,742,5,75,0,0,742,165,1,0,0,0,743,
        744,5,13,0,0,744,747,3,2,1,0,745,748,3,72,36,0,746,748,3,164,82,
        0,747,745,1,0,0,0,747,746,1,0,0,0,748,749,1,0,0,0,749,750,3,2,1,
        0,750,752,1,0,0,0,751,743,1,0,0,0,752,753,1,0,0,0,753,751,1,0,0,
        0,753,754,1,0,0,0,754,167,1,0,0,0,755,756,5,49,0,0,756,169,1,0,0,
        0,757,758,5,51,0,0,758,171,1,0,0,0,759,760,5,50,0,0,760,173,1,0,
        0,0,761,762,5,52,0,0,762,175,1,0,0,0,763,764,5,53,0,0,764,177,1,
        0,0,0,765,766,5,108,0,0,766,179,1,0,0,0,767,768,5,47,0,0,768,181,
        1,0,0,0,769,857,3,2,1,0,770,857,3,0,0,0,771,857,3,4,2,0,772,857,
        3,6,3,0,773,857,3,10,5,0,774,857,3,12,6,0,775,857,3,8,4,0,776,857,
        3,14,7,0,777,857,3,20,10,0,778,857,3,22,11,0,779,857,3,36,18,0,780,
        857,3,24,12,0,781,857,3,26,13,0,782,857,3,28,14,0,783,857,3,30,15,
        0,784,857,3,32,16,0,785,857,3,34,17,0,786,857,3,38,19,0,787,857,
        3,42,21,0,788,857,3,44,22,0,789,857,3,46,23,0,790,857,3,48,24,0,
        791,857,3,50,25,0,792,857,3,52,26,0,793,857,3,54,27,0,794,857,3,
        56,28,0,795,857,3,58,29,0,796,857,3,60,30,0,797,857,3,62,31,0,798,
        857,3,64,32,0,799,857,3,66,33,0,800,857,3,68,34,0,801,857,3,70,35,
        0,802,857,3,72,36,0,803,857,3,74,37,0,804,857,3,76,38,0,805,857,
        3,78,39,0,806,857,3,80,40,0,807,857,3,82,41,0,808,857,3,84,42,0,
        809,857,3,86,43,0,810,857,3,88,44,0,811,857,3,90,45,0,812,857,3,
        92,46,0,813,857,3,94,47,0,814,857,3,96,48,0,815,857,3,40,20,0,816,
        857,3,98,49,0,817,857,3,100,50,0,818,857,3,102,51,0,819,857,3,104,
        52,0,820,857,3,106,53,0,821,857,3,108,54,0,822,857,3,110,55,0,823,
        857,3,112,56,0,824,857,3,114,57,0,825,857,3,122,61,0,826,857,3,116,
        58,0,827,857,3,118,59,0,828,857,3,120,60,0,829,857,3,126,63,0,830,
        857,3,128,64,0,831,857,3,130,65,0,832,857,3,132,66,0,833,857,3,134,
        67,0,834,857,3,136,68,0,835,857,3,138,69,0,836,857,3,140,70,0,837,
        857,3,142,71,0,838,857,3,144,72,0,839,857,3,146,73,0,840,857,3,148,
        74,0,841,857,3,150,75,0,842,857,3,152,76,0,843,857,3,154,77,0,844,
        857,3,156,78,0,845,857,3,158,79,0,846,857,3,160,80,0,847,857,3,162,
        81,0,848,857,3,166,83,0,849,857,3,168,84,0,850,857,3,170,85,0,851,
        857,3,172,86,0,852,857,3,174,87,0,853,857,3,176,88,0,854,857,3,178,
        89,0,855,857,3,180,90,0,856,769,1,0,0,0,856,770,1,0,0,0,856,771,
        1,0,0,0,856,772,1,0,0,0,856,773,1,0,0,0,856,774,1,0,0,0,856,775,
        1,0,0,0,856,776,1,0,0,0,856,777,1,0,0,0,856,778,1,0,0,0,856,779,
        1,0,0,0,856,780,1,0,0,0,856,781,1,0,0,0,856,782,1,0,0,0,856,783,
        1,0,0,0,856,784,1,0,0,0,856,785,1,0,0,0,856,786,1,0,0,0,856,787,
        1,0,0,0,856,788,1,0,0,0,856,789,1,0,0,0,856,790,1,0,0,0,856,791,
        1,0,0,0,856,792,1,0,0,0,856,793,1,0,0,0,856,794,1,0,0,0,856,795,
        1,0,0,0,856,796,1,0,0,0,856,797,1,0,0,0,856,798,1,0,0,0,856,799,
        1,0,0,0,856,800,1,0,0,0,856,801,1,0,0,0,856,802,1,0,0,0,856,803,
        1,0,0,0,856,804,1,0,0,0,856,805,1,0,0,0,856,806,1,0,0,0,856,807,
        1,0,0,0,856,808,1,0,0,0,856,809,1,0,0,0,856,810,1,0,0,0,856,811,
        1,0,0,0,856,812,1,0,0,0,856,813,1,0,0,0,856,814,1,0,0,0,856,815,
        1,0,0,0,856,816,1,0,0,0,856,817,1,0,0,0,856,818,1,0,0,0,856,819,
        1,0,0,0,856,820,1,0,0,0,856,821,1,0,0,0,856,822,1,0,0,0,856,823,
        1,0,0,0,856,824,1,0,0,0,856,825,1,0,0,0,856,826,1,0,0,0,856,827,
        1,0,0,0,856,828,1,0,0,0,856,829,1,0,0,0,856,830,1,0,0,0,856,831,
        1,0,0,0,856,832,1,0,0,0,856,833,1,0,0,0,856,834,1,0,0,0,856,835,
        1,0,0,0,856,836,1,0,0,0,856,837,1,0,0,0,856,838,1,0,0,0,856,839,
        1,0,0,0,856,840,1,0,0,0,856,841,1,0,0,0,856,842,1,0,0,0,856,843,
        1,0,0,0,856,844,1,0,0,0,856,845,1,0,0,0,856,846,1,0,0,0,856,847,
        1,0,0,0,856,848,1,0,0,0,856,849,1,0,0,0,856,850,1,0,0,0,856,851,
        1,0,0,0,856,852,1,0,0,0,856,853,1,0,0,0,856,854,1,0,0,0,856,855,
        1,0,0,0,857,183,1,0,0,0,858,860,3,182,91,0,859,858,1,0,0,0,860,863,
        1,0,0,0,861,859,1,0,0,0,861,862,1,0,0,0,862,864,1,0,0,0,863,861,
        1,0,0,0,864,865,5,0,0,1,865,185,1,0,0,0,68,194,214,223,225,240,260,
        270,275,281,287,293,299,303,308,314,322,328,384,402,418,424,428,
        437,443,447,456,462,466,476,482,488,494,498,508,518,528,539,546,
        552,558,564,572,579,584,587,591,597,619,631,638,643,653,662,673,
        679,684,690,695,700,708,721,727,734,737,747,753,856,861
    ]

class TokenizeParser ( Parser ):

    grammarFileName = "Tokenize.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ "<INVALID>", "'\"'", "'{'", "'}'", "'['", "']'", "'('", 
                     "')'", "'if'", "'elif'", "'else'", "'[|'", "'|]'", 
                     "'|'", "'\\n'", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "<INVALID>", "<INVALID>", "'rec'", "'public'", 
                     "'private'", "'internal'", "'mutable'", "'let'", "'fun'", 
                     "'while'", "'do'", "'for'", "'to'", "'downto'", "'in'", 
                     "'$'", "'type'", "'module'", "'open'", "'namespace'", 
                     "'class'", "'end'", "'struct'", "'and'", "'interface'", 
                     "'get'", "'inherit'", "'override'", "'default'", "'abstract'", 
                     "'base'", "'async'", "'task'", "'new'", "'then'", "'this'", 
                     "'member'", "'seq'", "'Map'", "'set'", "'raise'", "'reraise'", 
                     "'failwith'", "'invalidArg'", "'val'", "'try'", "'finally'", 
                     "'match'", "'with'", "'use'", "'using'", "'exception'", 
                     "'of'", "'.'", "'..'", "'!'", "','", "';'", "':'", 
                     "'<-'", "'|>'", "'_'", "'->'", "'>>'", "'+'", "'-'", 
                     "'*'", "'/'", "'**'", "'%'", "'='", "'<>'", "'<'", 
                     "'>'", "'<='", "'>='", "'&&'", "'||'", "'<<<'", "'>>>'", 
                     "'&&&'", "'|||'", "'^^^'", "'~~~'", "'not'", "':?'" ]

    symbolicNames = [ "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                      "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                      "<INVALID>", "<INVALID>", "<INVALID>", "WHITE_SPACE", 
                      "COMMENT", "IDENTIFIER", "INT", "FLOAT", "INTERPOLATIONSIGN", 
                      "CHAR", "ESC", "BOOL", "UNIT", "REC", "PUBLIC", "PRIVATE", 
                      "INTERNAL", "MUTABLE", "LET", "FUN", "WHILE", "DO", 
                      "FOR", "TO", "DOWNTO", "IN", "DOLLAR", "TYPE", "MODULE", 
                      "OPEN", "NAMESPACE", "CLASS", "END", "STRUCT", "WITH_AND", 
                      "INTERFACE", "GET", "INHERIT", "OVERRIDE", "DEFAULT", 
                      "ABSTRACT", "BASE", "ASYNC", "TASK", "NEW", "THEN", 
                      "THIS", "MEMBER", "SEQ", "MAP", "SET", "RAISE", "RERAISE", 
                      "FAILWITH", "INVALIDARG", "VAL", "TRY", "FINALLY", 
                      "MATCH", "WITH", "USE", "USING", "EXCEPTION", "OF", 
                      "DOT", "DOTDOT", "EXCLAMATION_MARK", "COMMA", "SEMICOLON", 
                      "COLON", "ASSIGN", "PIPE", "MISSING_ARG", "RIGHT_ARROW", 
                      "COMPOS", "ADD", "MINUS", "MUL", "DIV", "POW", "MOD", 
                      "EQUAL", "NOT_EQUAL", "LESS", "GREATER", "LESS_EQUAL", 
                      "GREATER_EQUAL", "AND", "OR", "LSHIFT", "RSHIFT", 
                      "LOG_MUL", "LOG_ADD", "LOG_XOR", "LOG_NOT", "NOT", 
                      "COLON_Q" ]

    RULE_dot = 0
    RULE_dotIentifier = 1
    RULE_int = 2
    RULE_float = 3
    RULE_unit = 4
    RULE_bool = 5
    RULE_char = 6
    RULE_missing_arg = 7
    RULE_interpolationSign = 8
    RULE_dollar = 9
    RULE_string = 10
    RULE_attribute = 11
    RULE_round_brackets = 12
    RULE_rec = 13
    RULE_public = 14
    RULE_private = 15
    RULE_internal = 16
    RULE_mutable = 17
    RULE_let = 18
    RULE_fun = 19
    RULE_fun_type = 20
    RULE_typezation = 21
    RULE_if_then_elif_else = 22
    RULE_while_do = 23
    RULE_for = 24
    RULE_add = 25
    RULE_mul = 26
    RULE_div = 27
    RULE_minus = 28
    RULE_pow = 29
    RULE_mod = 30
    RULE_not_equal = 31
    RULE_less = 32
    RULE_less_equal = 33
    RULE_greater = 34
    RULE_greater_equal = 35
    RULE_equal = 36
    RULE_and = 37
    RULE_or = 38
    RULE_lshift = 39
    RULE_rshift = 40
    RULE_log_mul = 41
    RULE_log_add = 42
    RULE_log_xor = 43
    RULE_log_not = 44
    RULE_not = 45
    RULE_pipe = 46
    RULE_compos = 47
    RULE_assign = 48
    RULE_type = 49
    RULE_module = 50
    RULE_open = 51
    RULE_namespace = 52
    RULE_class = 53
    RULE_do = 54
    RULE_new = 55
    RULE_then = 56
    RULE_seq = 57
    RULE_list = 58
    RULE_array = 59
    RULE_map = 60
    RULE_generator = 61
    RULE_set = 62
    RULE_async_rule = 63
    RULE_task = 64
    RULE_exclamation_mark = 65
    RULE_match_with = 66
    RULE_try_with_finally = 67
    RULE_use = 68
    RULE_using = 69
    RULE_raise = 70
    RULE_reraise = 71
    RULE_failwith = 72
    RULE_invalidArg = 73
    RULE_exception_of = 74
    RULE_member = 75
    RULE_val = 76
    RULE_struct = 77
    RULE_with_get_set = 78
    RULE_tuple = 79
    RULE_with = 80
    RULE_record = 81
    RULE_of = 82
    RULE_enum = 83
    RULE_inherit = 84
    RULE_default = 85
    RULE_override = 86
    RULE_abstract = 87
    RULE_base = 88
    RULE_colon_q = 89
    RULE_interface = 90
    RULE_expression = 91
    RULE_exprs = 92

    ruleNames =  [ "dot", "dotIentifier", "int", "float", "unit", "bool", 
                   "char", "missing_arg", "interpolationSign", "dollar", 
                   "string", "attribute", "round_brackets", "rec", "public", 
                   "private", "internal", "mutable", "let", "fun", "fun_type", 
                   "typezation", "if_then_elif_else", "while_do", "for", 
                   "add", "mul", "div", "minus", "pow", "mod", "not_equal", 
                   "less", "less_equal", "greater", "greater_equal", "equal", 
                   "and", "or", "lshift", "rshift", "log_mul", "log_add", 
                   "log_xor", "log_not", "not", "pipe", "compos", "assign", 
                   "type", "module", "open", "namespace", "class", "do", 
                   "new", "then", "seq", "list", "array", "map", "generator", 
                   "set", "async_rule", "task", "exclamation_mark", "match_with", 
                   "try_with_finally", "use", "using", "raise", "reraise", 
                   "failwith", "invalidArg", "exception_of", "member", "val", 
                   "struct", "with_get_set", "tuple", "with", "record", 
                   "of", "enum", "inherit", "default", "override", "abstract", 
                   "base", "colon_q", "interface", "expression", "exprs" ]

    EOF = Token.EOF
    T__0=1
    T__1=2
    T__2=3
    T__3=4
    T__4=5
    T__5=6
    T__6=7
    T__7=8
    T__8=9
    T__9=10
    T__10=11
    T__11=12
    T__12=13
    T__13=14
    WHITE_SPACE=15
    COMMENT=16
    IDENTIFIER=17
    INT=18
    FLOAT=19
    INTERPOLATIONSIGN=20
    CHAR=21
    ESC=22
    BOOL=23
    UNIT=24
    REC=25
    PUBLIC=26
    PRIVATE=27
    INTERNAL=28
    MUTABLE=29
    LET=30
    FUN=31
    WHILE=32
    DO=33
    FOR=34
    TO=35
    DOWNTO=36
    IN=37
    DOLLAR=38
    TYPE=39
    MODULE=40
    OPEN=41
    NAMESPACE=42
    CLASS=43
    END=44
    STRUCT=45
    WITH_AND=46
    INTERFACE=47
    GET=48
    INHERIT=49
    OVERRIDE=50
    DEFAULT=51
    ABSTRACT=52
    BASE=53
    ASYNC=54
    TASK=55
    NEW=56
    THEN=57
    THIS=58
    MEMBER=59
    SEQ=60
    MAP=61
    SET=62
    RAISE=63
    RERAISE=64
    FAILWITH=65
    INVALIDARG=66
    VAL=67
    TRY=68
    FINALLY=69
    MATCH=70
    WITH=71
    USE=72
    USING=73
    EXCEPTION=74
    OF=75
    DOT=76
    DOTDOT=77
    EXCLAMATION_MARK=78
    COMMA=79
    SEMICOLON=80
    COLON=81
    ASSIGN=82
    PIPE=83
    MISSING_ARG=84
    RIGHT_ARROW=85
    COMPOS=86
    ADD=87
    MINUS=88
    MUL=89
    DIV=90
    POW=91
    MOD=92
    EQUAL=93
    NOT_EQUAL=94
    LESS=95
    GREATER=96
    LESS_EQUAL=97
    GREATER_EQUAL=98
    AND=99
    OR=100
    LSHIFT=101
    RSHIFT=102
    LOG_MUL=103
    LOG_ADD=104
    LOG_XOR=105
    LOG_NOT=106
    NOT=107
    COLON_Q=108

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.13.1")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None




    class DotContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def DOT(self):
            return self.getToken(TokenizeParser.DOT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_dot

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDot" ):
                listener.enterDot(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDot" ):
                listener.exitDot(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDot" ):
                return visitor.visitDot(self)
            else:
                return visitor.visitChildren(self)




    def dot(self):

        localctx = TokenizeParser.DotContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_dot)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 186
            self.match(TokenizeParser.DOT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class DotIentifierContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def IDENTIFIER(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.IDENTIFIER)
            else:
                return self.getToken(TokenizeParser.IDENTIFIER, i)

        def dot(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.DotContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.DotContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_dotIentifier

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDotIentifier" ):
                listener.enterDotIentifier(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDotIentifier" ):
                listener.exitDotIentifier(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDotIentifier" ):
                return visitor.visitDotIentifier(self)
            else:
                return visitor.visitChildren(self)




    def dotIentifier(self):

        localctx = TokenizeParser.DotIentifierContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_dotIentifier)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 188
            self.match(TokenizeParser.IDENTIFIER)
            self.state = 194
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,0,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 189
                    self.dot()
                    self.state = 190
                    self.match(TokenizeParser.IDENTIFIER) 
                self.state = 196
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,0,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class IntContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INT(self):
            return self.getToken(TokenizeParser.INT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_int

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInt" ):
                listener.enterInt(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInt" ):
                listener.exitInt(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInt" ):
                return visitor.visitInt(self)
            else:
                return visitor.visitChildren(self)




    def int_(self):

        localctx = TokenizeParser.IntContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_int)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 197
            self.match(TokenizeParser.INT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class FloatContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def FLOAT(self):
            return self.getToken(TokenizeParser.FLOAT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_float

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFloat" ):
                listener.enterFloat(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFloat" ):
                listener.exitFloat(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitFloat" ):
                return visitor.visitFloat(self)
            else:
                return visitor.visitChildren(self)




    def float_(self):

        localctx = TokenizeParser.FloatContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_float)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 199
            self.match(TokenizeParser.FLOAT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class UnitContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def UNIT(self):
            return self.getToken(TokenizeParser.UNIT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_unit

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterUnit" ):
                listener.enterUnit(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitUnit" ):
                listener.exitUnit(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitUnit" ):
                return visitor.visitUnit(self)
            else:
                return visitor.visitChildren(self)




    def unit(self):

        localctx = TokenizeParser.UnitContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_unit)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 201
            self.match(TokenizeParser.UNIT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class BoolContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def BOOL(self):
            return self.getToken(TokenizeParser.BOOL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_bool

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterBool" ):
                listener.enterBool(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitBool" ):
                listener.exitBool(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitBool" ):
                return visitor.visitBool(self)
            else:
                return visitor.visitChildren(self)




    def bool_(self):

        localctx = TokenizeParser.BoolContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_bool)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 203
            self.match(TokenizeParser.BOOL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class CharContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def CHAR(self):
            return self.getToken(TokenizeParser.CHAR, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_char

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterChar" ):
                listener.enterChar(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitChar" ):
                listener.exitChar(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitChar" ):
                return visitor.visitChar(self)
            else:
                return visitor.visitChildren(self)




    def char(self):

        localctx = TokenizeParser.CharContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_char)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 205
            self.match(TokenizeParser.CHAR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Missing_argContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MISSING_ARG(self):
            return self.getToken(TokenizeParser.MISSING_ARG, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_missing_arg

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMissing_arg" ):
                listener.enterMissing_arg(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMissing_arg" ):
                listener.exitMissing_arg(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMissing_arg" ):
                return visitor.visitMissing_arg(self)
            else:
                return visitor.visitChildren(self)




    def missing_arg(self):

        localctx = TokenizeParser.Missing_argContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_missing_arg)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 207
            self.match(TokenizeParser.MISSING_ARG)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class InterpolationSignContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INTERPOLATIONSIGN(self):
            return self.getToken(TokenizeParser.INTERPOLATIONSIGN, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_interpolationSign

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInterpolationSign" ):
                listener.enterInterpolationSign(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInterpolationSign" ):
                listener.exitInterpolationSign(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInterpolationSign" ):
                return visitor.visitInterpolationSign(self)
            else:
                return visitor.visitChildren(self)




    def interpolationSign(self):

        localctx = TokenizeParser.InterpolationSignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_interpolationSign)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 209
            self.match(TokenizeParser.INTERPOLATIONSIGN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class DollarContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def DOLLAR(self):
            return self.getToken(TokenizeParser.DOLLAR, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_dollar

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDollar" ):
                listener.enterDollar(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDollar" ):
                listener.exitDollar(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDollar" ):
                return visitor.visitDollar(self)
            else:
                return visitor.visitChildren(self)




    def dollar(self):

        localctx = TokenizeParser.DollarContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_dollar)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 211
            self.match(TokenizeParser.DOLLAR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class StringContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def dollar(self):
            return self.getTypedRuleContext(TokenizeParser.DollarContext,0)


        def interpolationSign(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.InterpolationSignContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.InterpolationSignContext,i)


        def CHAR(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.CHAR)
            else:
                return self.getToken(TokenizeParser.CHAR, i)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_string

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterString" ):
                listener.enterString(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitString" ):
                listener.exitString(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitString" ):
                return visitor.visitString(self)
            else:
                return visitor.visitChildren(self)




    def string(self):

        localctx = TokenizeParser.StringContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_string)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 214
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==38:
                self.state = 213
                self.dollar()


            self.state = 216
            self.match(TokenizeParser.T__0)
            self.state = 225
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & 3145732) != 0):
                self.state = 223
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [2]:
                    self.state = 217
                    self.match(TokenizeParser.T__1)
                    self.state = 218
                    self.expression()
                    self.state = 219
                    self.match(TokenizeParser.T__2)
                    pass
                elif token in [20]:
                    self.state = 221
                    self.interpolationSign()
                    pass
                elif token in [21]:
                    self.state = 222
                    self.match(TokenizeParser.CHAR)
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 227
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 228
            self.match(TokenizeParser.T__0)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AttributeContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LESS(self):
            return self.getToken(TokenizeParser.LESS, 0)

        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def GREATER(self):
            return self.getToken(TokenizeParser.GREATER, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_attribute

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAttribute" ):
                listener.enterAttribute(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAttribute" ):
                listener.exitAttribute(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitAttribute" ):
                return visitor.visitAttribute(self)
            else:
                return visitor.visitChildren(self)




    def attribute(self):

        localctx = TokenizeParser.AttributeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_attribute)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 230
            self.match(TokenizeParser.T__3)
            self.state = 231
            self.match(TokenizeParser.LESS)
            self.state = 232
            self.dotIentifier()
            self.state = 233
            self.match(TokenizeParser.GREATER)
            self.state = 234
            self.match(TokenizeParser.T__4)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Round_bracketsContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_round_brackets

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRound_brackets" ):
                listener.enterRound_brackets(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRound_brackets" ):
                listener.exitRound_brackets(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitRound_brackets" ):
                return visitor.visitRound_brackets(self)
            else:
                return visitor.visitChildren(self)




    def round_brackets(self):

        localctx = TokenizeParser.Round_bracketsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_round_brackets)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 236
            self.match(TokenizeParser.T__5)
            self.state = 238 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 237
                self.expression()
                self.state = 240 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 242
            self.match(TokenizeParser.T__6)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class RecContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def REC(self):
            return self.getToken(TokenizeParser.REC, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_rec

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRec" ):
                listener.enterRec(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRec" ):
                listener.exitRec(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitRec" ):
                return visitor.visitRec(self)
            else:
                return visitor.visitChildren(self)




    def rec(self):

        localctx = TokenizeParser.RecContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_rec)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 244
            self.match(TokenizeParser.REC)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class PublicContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def PUBLIC(self):
            return self.getToken(TokenizeParser.PUBLIC, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_public

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPublic" ):
                listener.enterPublic(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPublic" ):
                listener.exitPublic(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitPublic" ):
                return visitor.visitPublic(self)
            else:
                return visitor.visitChildren(self)




    def public(self):

        localctx = TokenizeParser.PublicContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_public)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 246
            self.match(TokenizeParser.PUBLIC)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class PrivateContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def PRIVATE(self):
            return self.getToken(TokenizeParser.PRIVATE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_private

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPrivate" ):
                listener.enterPrivate(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPrivate" ):
                listener.exitPrivate(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitPrivate" ):
                return visitor.visitPrivate(self)
            else:
                return visitor.visitChildren(self)




    def private(self):

        localctx = TokenizeParser.PrivateContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_private)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 248
            self.match(TokenizeParser.PRIVATE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class InternalContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INTERNAL(self):
            return self.getToken(TokenizeParser.INTERNAL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_internal

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInternal" ):
                listener.enterInternal(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInternal" ):
                listener.exitInternal(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInternal" ):
                return visitor.visitInternal(self)
            else:
                return visitor.visitChildren(self)




    def internal(self):

        localctx = TokenizeParser.InternalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_internal)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 250
            self.match(TokenizeParser.INTERNAL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class MutableContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MUTABLE(self):
            return self.getToken(TokenizeParser.MUTABLE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_mutable

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMutable" ):
                listener.enterMutable(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMutable" ):
                listener.exitMutable(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMutable" ):
                return visitor.visitMutable(self)
            else:
                return visitor.visitChildren(self)




    def mutable(self):

        localctx = TokenizeParser.MutableContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_mutable)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 252
            self.match(TokenizeParser.MUTABLE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class LetContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LET(self):
            return self.getToken(TokenizeParser.LET, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_let

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLet" ):
                listener.enterLet(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLet" ):
                listener.exitLet(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLet" ):
                return visitor.visitLet(self)
            else:
                return visitor.visitChildren(self)




    def let(self):

        localctx = TokenizeParser.LetContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_let)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 254
            self.match(TokenizeParser.LET)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class FunContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def FUN(self):
            return self.getToken(TokenizeParser.FUN, 0)

        def RIGHT_ARROW(self):
            return self.getToken(TokenizeParser.RIGHT_ARROW, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_fun

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFun" ):
                listener.enterFun(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFun" ):
                listener.exitFun(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitFun" ):
                return visitor.visitFun(self)
            else:
                return visitor.visitChildren(self)




    def fun(self):

        localctx = TokenizeParser.FunContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_fun)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 256
            self.match(TokenizeParser.FUN)
            self.state = 258 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 257
                self.expression()
                self.state = 260 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 262
            self.match(TokenizeParser.RIGHT_ARROW)
            self.state = 263
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Fun_typeContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def dotIentifier(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.DotIentifierContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,i)


        def RIGHT_ARROW(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.RIGHT_ARROW)
            else:
                return self.getToken(TokenizeParser.RIGHT_ARROW, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_fun_type

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFun_type" ):
                listener.enterFun_type(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFun_type" ):
                listener.exitFun_type(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitFun_type" ):
                return visitor.visitFun_type(self)
            else:
                return visitor.visitChildren(self)




    def fun_type(self):

        localctx = TokenizeParser.Fun_typeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_fun_type)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 265
            self.dotIentifier()
            self.state = 268 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 266
                    self.match(TokenizeParser.RIGHT_ARROW)
                    self.state = 267
                    self.dotIentifier()

                else:
                    raise NoViableAltException(self)
                self.state = 270 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,6,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class TypezationContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def COLON(self):
            return self.getToken(TokenizeParser.COLON, 0)

        def round_brackets(self):
            return self.getTypedRuleContext(TokenizeParser.Round_bracketsContext,0)


        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_typezation

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterTypezation" ):
                listener.enterTypezation(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitTypezation" ):
                listener.exitTypezation(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitTypezation" ):
                return visitor.visitTypezation(self)
            else:
                return visitor.visitChildren(self)




    def typezation(self):

        localctx = TokenizeParser.TypezationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 42, self.RULE_typezation)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 272
            self.match(TokenizeParser.COLON)
            self.state = 275
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [6]:
                self.state = 273
                self.round_brackets()
                pass
            elif token in [17]:
                self.state = 274
                self.dotIentifier()
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class If_then_elif_elseContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def THEN(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.THEN)
            else:
                return self.getToken(TokenizeParser.THEN, i)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_if_then_elif_else

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterIf_then_elif_else" ):
                listener.enterIf_then_elif_else(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitIf_then_elif_else" ):
                listener.exitIf_then_elif_else(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitIf_then_elif_else" ):
                return visitor.visitIf_then_elif_else(self)
            else:
                return visitor.visitChildren(self)




    def if_then_elif_else(self):

        localctx = TokenizeParser.If_then_elif_elseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 44, self.RULE_if_then_elif_else)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 277
            self.match(TokenizeParser.T__7)
            self.state = 279 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 278
                    self.expression()

                else:
                    raise NoViableAltException(self)
                self.state = 281 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,8,self._ctx)

            self.state = 283
            self.match(TokenizeParser.THEN)
            self.state = 285 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 284
                    self.expression()

                else:
                    raise NoViableAltException(self)
                self.state = 287 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,9,self._ctx)

            self.state = 303
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,12,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 289
                    self.match(TokenizeParser.T__8)
                    self.state = 291 
                    self._errHandler.sync(self)
                    _alt = 1
                    while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                        if _alt == 1:
                            self.state = 290
                            self.expression()

                        else:
                            raise NoViableAltException(self)
                        self.state = 293 
                        self._errHandler.sync(self)
                        _alt = self._interp.adaptivePredict(self._input,10,self._ctx)

                    self.state = 295
                    self.match(TokenizeParser.THEN)
                    self.state = 297 
                    self._errHandler.sync(self)
                    _alt = 1
                    while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                        if _alt == 1:
                            self.state = 296
                            self.expression()

                        else:
                            raise NoViableAltException(self)
                        self.state = 299 
                        self._errHandler.sync(self)
                        _alt = self._interp.adaptivePredict(self._input,11,self._ctx)
             
                self.state = 305
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,12,self._ctx)

            self.state = 308
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,13,self._ctx)
            if la_ == 1:
                self.state = 306
                self.match(TokenizeParser.T__9)
                self.state = 307
                self.expression()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class While_doContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def WHILE(self):
            return self.getToken(TokenizeParser.WHILE, 0)

        def DO(self):
            return self.getToken(TokenizeParser.DO, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_while_do

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterWhile_do" ):
                listener.enterWhile_do(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitWhile_do" ):
                listener.exitWhile_do(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitWhile_do" ):
                return visitor.visitWhile_do(self)
            else:
                return visitor.visitChildren(self)




    def while_do(self):

        localctx = TokenizeParser.While_doContext(self, self._ctx, self.state)
        self.enterRule(localctx, 46, self.RULE_while_do)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 310
            self.match(TokenizeParser.WHILE)
            self.state = 312 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 311
                    self.expression()

                else:
                    raise NoViableAltException(self)
                self.state = 314 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,14,self._ctx)

            self.state = 316
            self.match(TokenizeParser.DO)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ForContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def FOR(self):
            return self.getToken(TokenizeParser.FOR, 0)

        def DO(self):
            return self.getToken(TokenizeParser.DO, 0)

        def TO(self):
            return self.getToken(TokenizeParser.TO, 0)

        def DOWNTO(self):
            return self.getToken(TokenizeParser.DOWNTO, 0)

        def IN(self):
            return self.getToken(TokenizeParser.IN, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_for

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFor" ):
                listener.enterFor(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFor" ):
                listener.exitFor(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitFor" ):
                return visitor.visitFor(self)
            else:
                return visitor.visitChildren(self)




    def for_(self):

        localctx = TokenizeParser.ForContext(self, self._ctx, self.state)
        self.enterRule(localctx, 48, self.RULE_for)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 318
            self.match(TokenizeParser.FOR)
            self.state = 320 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 319
                self.expression()
                self.state = 322 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 324
            _la = self._input.LA(1)
            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & 240518168576) != 0)):
                self._errHandler.recoverInline(self)
            else:
                self._errHandler.reportMatch(self)
                self.consume()
            self.state = 326 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 325
                    self.expression()

                else:
                    raise NoViableAltException(self)
                self.state = 328 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,16,self._ctx)

            self.state = 330
            self.match(TokenizeParser.DO)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AddContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def ADD(self):
            return self.getToken(TokenizeParser.ADD, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_add

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAdd" ):
                listener.enterAdd(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAdd" ):
                listener.exitAdd(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitAdd" ):
                return visitor.visitAdd(self)
            else:
                return visitor.visitChildren(self)




    def add(self):

        localctx = TokenizeParser.AddContext(self, self._ctx, self.state)
        self.enterRule(localctx, 50, self.RULE_add)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 332
            self.match(TokenizeParser.ADD)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class MulContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MUL(self):
            return self.getToken(TokenizeParser.MUL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_mul

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMul" ):
                listener.enterMul(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMul" ):
                listener.exitMul(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMul" ):
                return visitor.visitMul(self)
            else:
                return visitor.visitChildren(self)




    def mul(self):

        localctx = TokenizeParser.MulContext(self, self._ctx, self.state)
        self.enterRule(localctx, 52, self.RULE_mul)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 334
            self.match(TokenizeParser.MUL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class DivContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def DIV(self):
            return self.getToken(TokenizeParser.DIV, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_div

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDiv" ):
                listener.enterDiv(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDiv" ):
                listener.exitDiv(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDiv" ):
                return visitor.visitDiv(self)
            else:
                return visitor.visitChildren(self)




    def div(self):

        localctx = TokenizeParser.DivContext(self, self._ctx, self.state)
        self.enterRule(localctx, 54, self.RULE_div)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 336
            self.match(TokenizeParser.DIV)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class MinusContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MINUS(self):
            return self.getToken(TokenizeParser.MINUS, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_minus

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMinus" ):
                listener.enterMinus(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMinus" ):
                listener.exitMinus(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMinus" ):
                return visitor.visitMinus(self)
            else:
                return visitor.visitChildren(self)




    def minus(self):

        localctx = TokenizeParser.MinusContext(self, self._ctx, self.state)
        self.enterRule(localctx, 56, self.RULE_minus)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 338
            self.match(TokenizeParser.MINUS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class PowContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def POW(self):
            return self.getToken(TokenizeParser.POW, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_pow

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPow" ):
                listener.enterPow(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPow" ):
                listener.exitPow(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitPow" ):
                return visitor.visitPow(self)
            else:
                return visitor.visitChildren(self)




    def pow_(self):

        localctx = TokenizeParser.PowContext(self, self._ctx, self.state)
        self.enterRule(localctx, 58, self.RULE_pow)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 340
            self.match(TokenizeParser.POW)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ModContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MOD(self):
            return self.getToken(TokenizeParser.MOD, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_mod

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMod" ):
                listener.enterMod(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMod" ):
                listener.exitMod(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMod" ):
                return visitor.visitMod(self)
            else:
                return visitor.visitChildren(self)




    def mod(self):

        localctx = TokenizeParser.ModContext(self, self._ctx, self.state)
        self.enterRule(localctx, 60, self.RULE_mod)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 342
            self.match(TokenizeParser.MOD)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Not_equalContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def NOT_EQUAL(self):
            return self.getToken(TokenizeParser.NOT_EQUAL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_not_equal

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNot_equal" ):
                listener.enterNot_equal(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNot_equal" ):
                listener.exitNot_equal(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitNot_equal" ):
                return visitor.visitNot_equal(self)
            else:
                return visitor.visitChildren(self)




    def not_equal(self):

        localctx = TokenizeParser.Not_equalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 62, self.RULE_not_equal)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 344
            self.match(TokenizeParser.NOT_EQUAL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class LessContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LESS(self):
            return self.getToken(TokenizeParser.LESS, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_less

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLess" ):
                listener.enterLess(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLess" ):
                listener.exitLess(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLess" ):
                return visitor.visitLess(self)
            else:
                return visitor.visitChildren(self)




    def less(self):

        localctx = TokenizeParser.LessContext(self, self._ctx, self.state)
        self.enterRule(localctx, 64, self.RULE_less)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 346
            self.match(TokenizeParser.LESS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Less_equalContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LESS_EQUAL(self):
            return self.getToken(TokenizeParser.LESS_EQUAL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_less_equal

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLess_equal" ):
                listener.enterLess_equal(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLess_equal" ):
                listener.exitLess_equal(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLess_equal" ):
                return visitor.visitLess_equal(self)
            else:
                return visitor.visitChildren(self)




    def less_equal(self):

        localctx = TokenizeParser.Less_equalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 66, self.RULE_less_equal)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 348
            self.match(TokenizeParser.LESS_EQUAL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class GreaterContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def GREATER(self):
            return self.getToken(TokenizeParser.GREATER, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_greater

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterGreater" ):
                listener.enterGreater(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitGreater" ):
                listener.exitGreater(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitGreater" ):
                return visitor.visitGreater(self)
            else:
                return visitor.visitChildren(self)




    def greater(self):

        localctx = TokenizeParser.GreaterContext(self, self._ctx, self.state)
        self.enterRule(localctx, 68, self.RULE_greater)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 350
            self.match(TokenizeParser.GREATER)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Greater_equalContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def GREATER_EQUAL(self):
            return self.getToken(TokenizeParser.GREATER_EQUAL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_greater_equal

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterGreater_equal" ):
                listener.enterGreater_equal(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitGreater_equal" ):
                listener.exitGreater_equal(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitGreater_equal" ):
                return visitor.visitGreater_equal(self)
            else:
                return visitor.visitChildren(self)




    def greater_equal(self):

        localctx = TokenizeParser.Greater_equalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 70, self.RULE_greater_equal)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 352
            self.match(TokenizeParser.GREATER_EQUAL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class EqualContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def EQUAL(self):
            return self.getToken(TokenizeParser.EQUAL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_equal

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEqual" ):
                listener.enterEqual(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEqual" ):
                listener.exitEqual(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitEqual" ):
                return visitor.visitEqual(self)
            else:
                return visitor.visitChildren(self)




    def equal(self):

        localctx = TokenizeParser.EqualContext(self, self._ctx, self.state)
        self.enterRule(localctx, 72, self.RULE_equal)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 354
            self.match(TokenizeParser.EQUAL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AndContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def AND(self):
            return self.getToken(TokenizeParser.AND, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_and

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAnd" ):
                listener.enterAnd(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAnd" ):
                listener.exitAnd(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitAnd" ):
                return visitor.visitAnd(self)
            else:
                return visitor.visitChildren(self)




    def and_(self):

        localctx = TokenizeParser.AndContext(self, self._ctx, self.state)
        self.enterRule(localctx, 74, self.RULE_and)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 356
            self.match(TokenizeParser.AND)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class OrContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def OR(self):
            return self.getToken(TokenizeParser.OR, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_or

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterOr" ):
                listener.enterOr(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitOr" ):
                listener.exitOr(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitOr" ):
                return visitor.visitOr(self)
            else:
                return visitor.visitChildren(self)




    def or_(self):

        localctx = TokenizeParser.OrContext(self, self._ctx, self.state)
        self.enterRule(localctx, 76, self.RULE_or)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 358
            self.match(TokenizeParser.OR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class LshiftContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LSHIFT(self):
            return self.getToken(TokenizeParser.LSHIFT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_lshift

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLshift" ):
                listener.enterLshift(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLshift" ):
                listener.exitLshift(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLshift" ):
                return visitor.visitLshift(self)
            else:
                return visitor.visitChildren(self)




    def lshift(self):

        localctx = TokenizeParser.LshiftContext(self, self._ctx, self.state)
        self.enterRule(localctx, 78, self.RULE_lshift)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 360
            self.match(TokenizeParser.LSHIFT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class RshiftContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def RSHIFT(self):
            return self.getToken(TokenizeParser.RSHIFT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_rshift

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRshift" ):
                listener.enterRshift(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRshift" ):
                listener.exitRshift(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitRshift" ):
                return visitor.visitRshift(self)
            else:
                return visitor.visitChildren(self)




    def rshift(self):

        localctx = TokenizeParser.RshiftContext(self, self._ctx, self.state)
        self.enterRule(localctx, 80, self.RULE_rshift)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 362
            self.match(TokenizeParser.RSHIFT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Log_mulContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LOG_MUL(self):
            return self.getToken(TokenizeParser.LOG_MUL, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_log_mul

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLog_mul" ):
                listener.enterLog_mul(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLog_mul" ):
                listener.exitLog_mul(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLog_mul" ):
                return visitor.visitLog_mul(self)
            else:
                return visitor.visitChildren(self)




    def log_mul(self):

        localctx = TokenizeParser.Log_mulContext(self, self._ctx, self.state)
        self.enterRule(localctx, 82, self.RULE_log_mul)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 364
            self.match(TokenizeParser.LOG_MUL)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Log_addContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LOG_ADD(self):
            return self.getToken(TokenizeParser.LOG_ADD, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_log_add

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLog_add" ):
                listener.enterLog_add(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLog_add" ):
                listener.exitLog_add(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLog_add" ):
                return visitor.visitLog_add(self)
            else:
                return visitor.visitChildren(self)




    def log_add(self):

        localctx = TokenizeParser.Log_addContext(self, self._ctx, self.state)
        self.enterRule(localctx, 84, self.RULE_log_add)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 366
            self.match(TokenizeParser.LOG_ADD)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Log_xorContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LOG_XOR(self):
            return self.getToken(TokenizeParser.LOG_XOR, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_log_xor

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLog_xor" ):
                listener.enterLog_xor(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLog_xor" ):
                listener.exitLog_xor(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLog_xor" ):
                return visitor.visitLog_xor(self)
            else:
                return visitor.visitChildren(self)




    def log_xor(self):

        localctx = TokenizeParser.Log_xorContext(self, self._ctx, self.state)
        self.enterRule(localctx, 86, self.RULE_log_xor)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 368
            self.match(TokenizeParser.LOG_XOR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Log_notContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def LOG_NOT(self):
            return self.getToken(TokenizeParser.LOG_NOT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_log_not

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLog_not" ):
                listener.enterLog_not(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLog_not" ):
                listener.exitLog_not(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitLog_not" ):
                return visitor.visitLog_not(self)
            else:
                return visitor.visitChildren(self)




    def log_not(self):

        localctx = TokenizeParser.Log_notContext(self, self._ctx, self.state)
        self.enterRule(localctx, 88, self.RULE_log_not)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 370
            self.match(TokenizeParser.LOG_NOT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class NotContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def NOT(self):
            return self.getToken(TokenizeParser.NOT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_not

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNot" ):
                listener.enterNot(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNot" ):
                listener.exitNot(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitNot" ):
                return visitor.visitNot(self)
            else:
                return visitor.visitChildren(self)




    def not_(self):

        localctx = TokenizeParser.NotContext(self, self._ctx, self.state)
        self.enterRule(localctx, 90, self.RULE_not)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 372
            self.match(TokenizeParser.NOT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class PipeContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def PIPE(self):
            return self.getToken(TokenizeParser.PIPE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_pipe

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPipe" ):
                listener.enterPipe(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPipe" ):
                listener.exitPipe(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitPipe" ):
                return visitor.visitPipe(self)
            else:
                return visitor.visitChildren(self)




    def pipe(self):

        localctx = TokenizeParser.PipeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 92, self.RULE_pipe)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 374
            self.match(TokenizeParser.PIPE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ComposContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def COMPOS(self):
            return self.getToken(TokenizeParser.COMPOS, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_compos

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterCompos" ):
                listener.enterCompos(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitCompos" ):
                listener.exitCompos(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitCompos" ):
                return visitor.visitCompos(self)
            else:
                return visitor.visitChildren(self)




    def compos(self):

        localctx = TokenizeParser.ComposContext(self, self._ctx, self.state)
        self.enterRule(localctx, 94, self.RULE_compos)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 376
            self.match(TokenizeParser.COMPOS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AssignContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def ASSIGN(self):
            return self.getToken(TokenizeParser.ASSIGN, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_assign

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAssign" ):
                listener.enterAssign(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAssign" ):
                listener.exitAssign(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitAssign" ):
                return visitor.visitAssign(self)
            else:
                return visitor.visitChildren(self)




    def assign(self):

        localctx = TokenizeParser.AssignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 96, self.RULE_assign)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 378
            self.match(TokenizeParser.ASSIGN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class TypeContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TYPE(self):
            return self.getToken(TokenizeParser.TYPE, 0)

        def EQUAL(self):
            return self.getToken(TokenizeParser.EQUAL, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_type

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterType" ):
                listener.enterType(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitType" ):
                listener.exitType(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitType" ):
                return visitor.visitType(self)
            else:
                return visitor.visitChildren(self)




    def type_(self):

        localctx = TokenizeParser.TypeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 98, self.RULE_type)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 380
            self.match(TokenizeParser.TYPE)
            self.state = 382 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 381
                    self.expression()

                else:
                    raise NoViableAltException(self)
                self.state = 384 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,17,self._ctx)

            self.state = 386
            self.match(TokenizeParser.EQUAL)
            self.state = 387
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ModuleContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MODULE(self):
            return self.getToken(TokenizeParser.MODULE, 0)

        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_module

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterModule" ):
                listener.enterModule(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitModule" ):
                listener.exitModule(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitModule" ):
                return visitor.visitModule(self)
            else:
                return visitor.visitChildren(self)




    def module(self):

        localctx = TokenizeParser.ModuleContext(self, self._ctx, self.state)
        self.enterRule(localctx, 100, self.RULE_module)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 389
            self.match(TokenizeParser.MODULE)
            self.state = 390
            self.dotIentifier()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class OpenContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def OPEN(self):
            return self.getToken(TokenizeParser.OPEN, 0)

        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_open

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterOpen" ):
                listener.enterOpen(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitOpen" ):
                listener.exitOpen(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitOpen" ):
                return visitor.visitOpen(self)
            else:
                return visitor.visitChildren(self)




    def open_(self):

        localctx = TokenizeParser.OpenContext(self, self._ctx, self.state)
        self.enterRule(localctx, 102, self.RULE_open)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 392
            self.match(TokenizeParser.OPEN)
            self.state = 393
            self.dotIentifier()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class NamespaceContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def NAMESPACE(self):
            return self.getToken(TokenizeParser.NAMESPACE, 0)

        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_namespace

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNamespace" ):
                listener.enterNamespace(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNamespace" ):
                listener.exitNamespace(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitNamespace" ):
                return visitor.visitNamespace(self)
            else:
                return visitor.visitChildren(self)




    def namespace(self):

        localctx = TokenizeParser.NamespaceContext(self, self._ctx, self.state)
        self.enterRule(localctx, 104, self.RULE_namespace)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 395
            self.match(TokenizeParser.NAMESPACE)
            self.state = 396
            self.dotIentifier()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ClassContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def CLASS(self):
            return self.getToken(TokenizeParser.CLASS, 0)

        def END(self):
            return self.getToken(TokenizeParser.END, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_class

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClass" ):
                listener.enterClass(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClass" ):
                listener.exitClass(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitClass" ):
                return visitor.visitClass(self)
            else:
                return visitor.visitChildren(self)




    def class_(self):

        localctx = TokenizeParser.ClassContext(self, self._ctx, self.state)
        self.enterRule(localctx, 106, self.RULE_class)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 398
            self.match(TokenizeParser.CLASS)
            self.state = 400 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 399
                self.expression()
                self.state = 402 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 404
            self.match(TokenizeParser.END)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class DoContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def DO(self):
            return self.getToken(TokenizeParser.DO, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_do

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDo" ):
                listener.enterDo(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDo" ):
                listener.exitDo(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDo" ):
                return visitor.visitDo(self)
            else:
                return visitor.visitChildren(self)




    def do(self):

        localctx = TokenizeParser.DoContext(self, self._ctx, self.state)
        self.enterRule(localctx, 108, self.RULE_do)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 406
            self.match(TokenizeParser.DO)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class NewContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def NEW(self):
            return self.getToken(TokenizeParser.NEW, 0)

        def expression(self):
            return self.getTypedRuleContext(TokenizeParser.ExpressionContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_new

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNew" ):
                listener.enterNew(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNew" ):
                listener.exitNew(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitNew" ):
                return visitor.visitNew(self)
            else:
                return visitor.visitChildren(self)




    def new(self):

        localctx = TokenizeParser.NewContext(self, self._ctx, self.state)
        self.enterRule(localctx, 110, self.RULE_new)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 408
            self.match(TokenizeParser.NEW)
            self.state = 409
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ThenContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def THEN(self):
            return self.getToken(TokenizeParser.THEN, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_then

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterThen" ):
                listener.enterThen(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitThen" ):
                listener.exitThen(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitThen" ):
                return visitor.visitThen(self)
            else:
                return visitor.visitChildren(self)




    def then(self):

        localctx = TokenizeParser.ThenContext(self, self._ctx, self.state)
        self.enterRule(localctx, 112, self.RULE_then)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 411
            self.match(TokenizeParser.THEN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class SeqContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def SEQ(self):
            return self.getToken(TokenizeParser.SEQ, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def SEMICOLON(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.SEMICOLON)
            else:
                return self.getToken(TokenizeParser.SEMICOLON, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_seq

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterSeq" ):
                listener.enterSeq(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitSeq" ):
                listener.exitSeq(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitSeq" ):
                return visitor.visitSeq(self)
            else:
                return visitor.visitChildren(self)




    def seq(self):

        localctx = TokenizeParser.SeqContext(self, self._ctx, self.state)
        self.enterRule(localctx, 114, self.RULE_seq)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 413
            self.match(TokenizeParser.SEQ)
            self.state = 414
            self.match(TokenizeParser.T__1)
            self.state = 416 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 415
                self.expression()
                self.state = 418 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 428
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==80:
                self.state = 420
                self.match(TokenizeParser.SEMICOLON)
                self.state = 422 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while True:
                    self.state = 421
                    self.expression()
                    self.state = 424 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                        break

                self.state = 430
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 431
            self.match(TokenizeParser.T__2)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ListContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def SEMICOLON(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.SEMICOLON)
            else:
                return self.getToken(TokenizeParser.SEMICOLON, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_list

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterList" ):
                listener.enterList(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitList" ):
                listener.exitList(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitList" ):
                return visitor.visitList(self)
            else:
                return visitor.visitChildren(self)




    def list_(self):

        localctx = TokenizeParser.ListContext(self, self._ctx, self.state)
        self.enterRule(localctx, 116, self.RULE_list)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 433
            self.match(TokenizeParser.T__3)
            self.state = 435 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 434
                self.expression()
                self.state = 437 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 447
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==80:
                self.state = 439
                self.match(TokenizeParser.SEMICOLON)
                self.state = 441 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while True:
                    self.state = 440
                    self.expression()
                    self.state = 443 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                        break

                self.state = 449
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 450
            self.match(TokenizeParser.T__4)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ArrayContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def SEMICOLON(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.SEMICOLON)
            else:
                return self.getToken(TokenizeParser.SEMICOLON, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_array

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterArray" ):
                listener.enterArray(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitArray" ):
                listener.exitArray(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitArray" ):
                return visitor.visitArray(self)
            else:
                return visitor.visitChildren(self)




    def array(self):

        localctx = TokenizeParser.ArrayContext(self, self._ctx, self.state)
        self.enterRule(localctx, 118, self.RULE_array)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 452
            self.match(TokenizeParser.T__10)
            self.state = 454 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 453
                self.expression()
                self.state = 456 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 466
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==80:
                self.state = 458
                self.match(TokenizeParser.SEMICOLON)
                self.state = 460 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while True:
                    self.state = 459
                    self.expression()
                    self.state = 462 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                        break

                self.state = 468
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 469
            self.match(TokenizeParser.T__11)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class MapContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MAP(self):
            return self.getToken(TokenizeParser.MAP, 0)

        def COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.COMMA)
            else:
                return self.getToken(TokenizeParser.COMMA, i)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def SEMICOLON(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.SEMICOLON)
            else:
                return self.getToken(TokenizeParser.SEMICOLON, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_map

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMap" ):
                listener.enterMap(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMap" ):
                listener.exitMap(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMap" ):
                return visitor.visitMap(self)
            else:
                return visitor.visitChildren(self)




    def map_(self):

        localctx = TokenizeParser.MapContext(self, self._ctx, self.state)
        self.enterRule(localctx, 120, self.RULE_map)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 471
            self.match(TokenizeParser.MAP)
            self.state = 472
            self.match(TokenizeParser.T__3)
            self.state = 474 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 473
                self.expression()
                self.state = 476 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 478
            self.match(TokenizeParser.COMMA)
            self.state = 480 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 479
                self.expression()
                self.state = 482 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                    break

            self.state = 498
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==80:
                self.state = 484
                self.match(TokenizeParser.SEMICOLON)
                self.state = 486 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while True:
                    self.state = 485
                    self.expression()
                    self.state = 488 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                        break

                self.state = 490
                self.match(TokenizeParser.COMMA)
                self.state = 492 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while True:
                    self.state = 491
                    self.expression()
                    self.state = 494 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                        break

                self.state = 500
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 501
            self.match(TokenizeParser.T__4)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class GeneratorContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def DOTDOT(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.DOTDOT)
            else:
                return self.getToken(TokenizeParser.DOTDOT, i)

        def INT(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.INT)
            else:
                return self.getToken(TokenizeParser.INT, i)

        def FLOAT(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.FLOAT)
            else:
                return self.getToken(TokenizeParser.FLOAT, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_generator

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterGenerator" ):
                listener.enterGenerator(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitGenerator" ):
                listener.exitGenerator(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitGenerator" ):
                return visitor.visitGenerator(self)
            else:
                return visitor.visitChildren(self)




    def generator(self):

        localctx = TokenizeParser.GeneratorContext(self, self._ctx, self.state)
        self.enterRule(localctx, 122, self.RULE_generator)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 503
            _la = self._input.LA(1)
            if not(_la==18 or _la==19):
                self._errHandler.recoverInline(self)
            else:
                self._errHandler.reportMatch(self)
                self.consume()
            self.state = 504
            self.match(TokenizeParser.DOTDOT)
            self.state = 505
            _la = self._input.LA(1)
            if not(_la==18 or _la==19):
                self._errHandler.recoverInline(self)
            else:
                self._errHandler.reportMatch(self)
                self.consume()
            self.state = 508
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==77:
                self.state = 506
                self.match(TokenizeParser.DOTDOT)
                self.state = 507
                _la = self._input.LA(1)
                if not(_la==18 or _la==19):
                    self._errHandler.recoverInline(self)
                else:
                    self._errHandler.reportMatch(self)
                    self.consume()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class SetContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def SET(self):
            return self.getToken(TokenizeParser.SET, 0)

        def expression(self):
            return self.getTypedRuleContext(TokenizeParser.ExpressionContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_set

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterSet" ):
                listener.enterSet(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitSet" ):
                listener.exitSet(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitSet" ):
                return visitor.visitSet(self)
            else:
                return visitor.visitChildren(self)




    def set_(self):

        localctx = TokenizeParser.SetContext(self, self._ctx, self.state)
        self.enterRule(localctx, 124, self.RULE_set)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 510
            self.match(TokenizeParser.SET)
            self.state = 511
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Async_ruleContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def ASYNC(self):
            return self.getToken(TokenizeParser.ASYNC, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_async_rule

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAsync_rule" ):
                listener.enterAsync_rule(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAsync_rule" ):
                listener.exitAsync_rule(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitAsync_rule" ):
                return visitor.visitAsync_rule(self)
            else:
                return visitor.visitChildren(self)




    def async_rule(self):

        localctx = TokenizeParser.Async_ruleContext(self, self._ctx, self.state)
        self.enterRule(localctx, 126, self.RULE_async_rule)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 513
            self.match(TokenizeParser.ASYNC)
            self.state = 514
            self.match(TokenizeParser.T__1)
            self.state = 518
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0):
                self.state = 515
                self.expression()
                self.state = 520
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 521
            self.match(TokenizeParser.T__2)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class TaskContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TASK(self):
            return self.getToken(TokenizeParser.TASK, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_task

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterTask" ):
                listener.enterTask(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitTask" ):
                listener.exitTask(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitTask" ):
                return visitor.visitTask(self)
            else:
                return visitor.visitChildren(self)




    def task(self):

        localctx = TokenizeParser.TaskContext(self, self._ctx, self.state)
        self.enterRule(localctx, 128, self.RULE_task)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 523
            self.match(TokenizeParser.TASK)
            self.state = 524
            self.match(TokenizeParser.T__1)
            self.state = 528
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0):
                self.state = 525
                self.expression()
                self.state = 530
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 531
            self.match(TokenizeParser.T__2)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Exclamation_markContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def EXCLAMATION_MARK(self):
            return self.getToken(TokenizeParser.EXCLAMATION_MARK, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_exclamation_mark

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExclamation_mark" ):
                listener.enterExclamation_mark(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExclamation_mark" ):
                listener.exitExclamation_mark(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitExclamation_mark" ):
                return visitor.visitExclamation_mark(self)
            else:
                return visitor.visitChildren(self)




    def exclamation_mark(self):

        localctx = TokenizeParser.Exclamation_markContext(self, self._ctx, self.state)
        self.enterRule(localctx, 130, self.RULE_exclamation_mark)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 533
            self.match(TokenizeParser.EXCLAMATION_MARK)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Match_withContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MATCH(self):
            return self.getToken(TokenizeParser.MATCH, 0)

        def WITH(self):
            return self.getToken(TokenizeParser.WITH, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def RIGHT_ARROW(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.RIGHT_ARROW)
            else:
                return self.getToken(TokenizeParser.RIGHT_ARROW, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_match_with

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMatch_with" ):
                listener.enterMatch_with(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMatch_with" ):
                listener.exitMatch_with(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMatch_with" ):
                return visitor.visitMatch_with(self)
            else:
                return visitor.visitChildren(self)




    def match_with(self):

        localctx = TokenizeParser.Match_withContext(self, self._ctx, self.state)
        self.enterRule(localctx, 132, self.RULE_match_with)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 535
            self.match(TokenizeParser.MATCH)
            self.state = 537 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 536
                    self.expression()

                else:
                    raise NoViableAltException(self)
                self.state = 539 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,36,self._ctx)

            self.state = 541
            self.match(TokenizeParser.WITH)
            self.state = 556 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 542
                    self.match(TokenizeParser.T__12)
                    self.state = 544 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    while True:
                        self.state = 543
                        self.expression()
                        self.state = 546 
                        self._errHandler.sync(self)
                        _la = self._input.LA(1)
                        if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                            break

                    self.state = 548
                    self.match(TokenizeParser.RIGHT_ARROW)
                    self.state = 550 
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)
                    while True:
                        self.state = 549
                        self.expression()
                        self.state = 552 
                        self._errHandler.sync(self)
                        _la = self._input.LA(1)
                        if not ((((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0)):
                            break

                    self.state = 554
                    self.match(TokenizeParser.T__13)

                else:
                    raise NoViableAltException(self)
                self.state = 558 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,39,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Try_with_finallyContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TRY(self):
            return self.getToken(TokenizeParser.TRY, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def WITH(self):
            return self.getToken(TokenizeParser.WITH, 0)

        def FINALLY(self):
            return self.getToken(TokenizeParser.FINALLY, 0)

        def RIGHT_ARROW(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.RIGHT_ARROW)
            else:
                return self.getToken(TokenizeParser.RIGHT_ARROW, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_try_with_finally

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterTry_with_finally" ):
                listener.enterTry_with_finally(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitTry_with_finally" ):
                listener.exitTry_with_finally(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitTry_with_finally" ):
                return visitor.visitTry_with_finally(self)
            else:
                return visitor.visitChildren(self)




    def try_with_finally(self):

        localctx = TokenizeParser.Try_with_finallyContext(self, self._ctx, self.state)
        self.enterRule(localctx, 134, self.RULE_try_with_finally)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 560
            self.match(TokenizeParser.TRY)
            self.state = 564
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,40,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 561
                    self.expression() 
                self.state = 566
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,40,self._ctx)

            self.state = 587
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,44,self._ctx)
            if la_ == 1:
                self.state = 567
                self.match(TokenizeParser.WITH)
                self.state = 584
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,43,self._ctx)
                while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                    if _alt==1:
                        self.state = 568
                        self.match(TokenizeParser.T__12)
                        self.state = 572
                        self._errHandler.sync(self)
                        _la = self._input.LA(1)
                        while (((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0):
                            self.state = 569
                            self.expression()
                            self.state = 574
                            self._errHandler.sync(self)
                            _la = self._input.LA(1)

                        self.state = 575
                        self.match(TokenizeParser.RIGHT_ARROW)
                        self.state = 579
                        self._errHandler.sync(self)
                        _alt = self._interp.adaptivePredict(self._input,42,self._ctx)
                        while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                            if _alt==1:
                                self.state = 576
                                self.expression() 
                            self.state = 581
                            self._errHandler.sync(self)
                            _alt = self._interp.adaptivePredict(self._input,42,self._ctx)
                 
                    self.state = 586
                    self._errHandler.sync(self)
                    _alt = self._interp.adaptivePredict(self._input,43,self._ctx)



            self.state = 591
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,45,self._ctx)
            if la_ == 1:
                self.state = 589
                self.match(TokenizeParser.FINALLY)
                self.state = 590
                self.expression()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class UseContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def USE(self):
            return self.getToken(TokenizeParser.USE, 0)

        def EQUAL(self):
            return self.getToken(TokenizeParser.EQUAL, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_use

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterUse" ):
                listener.enterUse(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitUse" ):
                listener.exitUse(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitUse" ):
                return visitor.visitUse(self)
            else:
                return visitor.visitChildren(self)




    def use(self):

        localctx = TokenizeParser.UseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 136, self.RULE_use)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 593
            self.match(TokenizeParser.USE)
            self.state = 597
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,46,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 594
                    self.expression() 
                self.state = 599
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,46,self._ctx)

            self.state = 600
            self.match(TokenizeParser.EQUAL)
            self.state = 601
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class UsingContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def USING(self):
            return self.getToken(TokenizeParser.USING, 0)

        def round_brackets(self):
            return self.getTypedRuleContext(TokenizeParser.Round_bracketsContext,0)


        def expression(self):
            return self.getTypedRuleContext(TokenizeParser.ExpressionContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_using

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterUsing" ):
                listener.enterUsing(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitUsing" ):
                listener.exitUsing(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitUsing" ):
                return visitor.visitUsing(self)
            else:
                return visitor.visitChildren(self)




    def using(self):

        localctx = TokenizeParser.UsingContext(self, self._ctx, self.state)
        self.enterRule(localctx, 138, self.RULE_using)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 603
            self.match(TokenizeParser.USING)
            self.state = 604
            self.round_brackets()
            self.state = 605
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class RaiseContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def RAISE(self):
            return self.getToken(TokenizeParser.RAISE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_raise

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRaise" ):
                listener.enterRaise(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRaise" ):
                listener.exitRaise(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitRaise" ):
                return visitor.visitRaise(self)
            else:
                return visitor.visitChildren(self)




    def raise_(self):

        localctx = TokenizeParser.RaiseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 140, self.RULE_raise)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 607
            self.match(TokenizeParser.RAISE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ReraiseContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def RERAISE(self):
            return self.getToken(TokenizeParser.RERAISE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_reraise

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterReraise" ):
                listener.enterReraise(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitReraise" ):
                listener.exitReraise(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitReraise" ):
                return visitor.visitReraise(self)
            else:
                return visitor.visitChildren(self)




    def reraise(self):

        localctx = TokenizeParser.ReraiseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 142, self.RULE_reraise)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 609
            self.match(TokenizeParser.RERAISE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class FailwithContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def FAILWITH(self):
            return self.getToken(TokenizeParser.FAILWITH, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_failwith

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFailwith" ):
                listener.enterFailwith(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFailwith" ):
                listener.exitFailwith(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitFailwith" ):
                return visitor.visitFailwith(self)
            else:
                return visitor.visitChildren(self)




    def failwith(self):

        localctx = TokenizeParser.FailwithContext(self, self._ctx, self.state)
        self.enterRule(localctx, 144, self.RULE_failwith)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 611
            self.match(TokenizeParser.FAILWITH)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class InvalidArgContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INVALIDARG(self):
            return self.getToken(TokenizeParser.INVALIDARG, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_invalidArg

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInvalidArg" ):
                listener.enterInvalidArg(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInvalidArg" ):
                listener.exitInvalidArg(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInvalidArg" ):
                return visitor.visitInvalidArg(self)
            else:
                return visitor.visitChildren(self)




    def invalidArg(self):

        localctx = TokenizeParser.InvalidArgContext(self, self._ctx, self.state)
        self.enterRule(localctx, 146, self.RULE_invalidArg)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 613
            self.match(TokenizeParser.INVALIDARG)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Exception_ofContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def EXCEPTION(self):
            return self.getToken(TokenizeParser.EXCEPTION, 0)

        def OF(self):
            return self.getToken(TokenizeParser.OF, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_exception_of

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterException_of" ):
                listener.enterException_of(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitException_of" ):
                listener.exitException_of(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitException_of" ):
                return visitor.visitException_of(self)
            else:
                return visitor.visitChildren(self)




    def exception_of(self):

        localctx = TokenizeParser.Exception_ofContext(self, self._ctx, self.state)
        self.enterRule(localctx, 148, self.RULE_exception_of)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 615
            self.match(TokenizeParser.EXCEPTION)
            self.state = 619
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0):
                self.state = 616
                self.expression()
                self.state = 621
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 622
            self.match(TokenizeParser.OF)
            self.state = 623
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class MemberContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def MEMBER(self):
            return self.getToken(TokenizeParser.MEMBER, 0)

        def dot(self):
            return self.getTypedRuleContext(TokenizeParser.DotContext,0)


        def equal(self):
            return self.getTypedRuleContext(TokenizeParser.EqualContext,0)


        def expression(self):
            return self.getTypedRuleContext(TokenizeParser.ExpressionContext,0)


        def THIS(self):
            return self.getToken(TokenizeParser.THIS, 0)

        def MISSING_ARG(self):
            return self.getToken(TokenizeParser.MISSING_ARG, 0)

        def dotIentifier(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.DotIentifierContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_member

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMember" ):
                listener.enterMember(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMember" ):
                listener.exitMember(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitMember" ):
                return visitor.visitMember(self)
            else:
                return visitor.visitChildren(self)




    def member(self):

        localctx = TokenizeParser.MemberContext(self, self._ctx, self.state)
        self.enterRule(localctx, 150, self.RULE_member)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 625
            self.match(TokenizeParser.MEMBER)
            self.state = 626
            _la = self._input.LA(1)
            if not(_la==58 or _la==84):
                self._errHandler.recoverInline(self)
            else:
                self._errHandler.reportMatch(self)
                self.consume()
            self.state = 627
            self.dot()
            self.state = 629 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 628
                self.dotIentifier()
                self.state = 631 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==17):
                    break

            self.state = 633
            self.equal()
            self.state = 634
            self.expression()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ValContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def VAL(self):
            return self.getToken(TokenizeParser.VAL, 0)

        def dotIentifier(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.DotIentifierContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,i)


        def COLON(self):
            return self.getToken(TokenizeParser.COLON, 0)

        def mutable(self):
            return self.getTypedRuleContext(TokenizeParser.MutableContext,0)


        def internal(self):
            return self.getTypedRuleContext(TokenizeParser.InternalContext,0)


        def public(self):
            return self.getTypedRuleContext(TokenizeParser.PublicContext,0)


        def private(self):
            return self.getTypedRuleContext(TokenizeParser.PrivateContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_val

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVal" ):
                listener.enterVal(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVal" ):
                listener.exitVal(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitVal" ):
                return visitor.visitVal(self)
            else:
                return visitor.visitChildren(self)




    def val(self):

        localctx = TokenizeParser.ValContext(self, self._ctx, self.state)
        self.enterRule(localctx, 152, self.RULE_val)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 636
            self.match(TokenizeParser.VAL)
            self.state = 638
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==29:
                self.state = 637
                self.mutable()


            self.state = 643
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [28]:
                self.state = 640
                self.internal()
                pass
            elif token in [26]:
                self.state = 641
                self.public()
                pass
            elif token in [27]:
                self.state = 642
                self.private()
                pass
            elif token in [17]:
                pass
            else:
                pass
            self.state = 645
            self.dotIentifier()
            self.state = 646
            self.match(TokenizeParser.COLON)
            self.state = 647
            self.dotIentifier()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class StructContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def STRUCT(self):
            return self.getToken(TokenizeParser.STRUCT, 0)

        def END(self):
            return self.getToken(TokenizeParser.END, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_struct

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterStruct" ):
                listener.enterStruct(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitStruct" ):
                listener.exitStruct(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitStruct" ):
                return visitor.visitStruct(self)
            else:
                return visitor.visitChildren(self)




    def struct(self):

        localctx = TokenizeParser.StructContext(self, self._ctx, self.state)
        self.enterRule(localctx, 154, self.RULE_struct)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 649
            self.match(TokenizeParser.STRUCT)
            self.state = 653
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0):
                self.state = 650
                self.expression()
                self.state = 655
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 656
            self.match(TokenizeParser.END)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class With_get_setContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def WITH(self):
            return self.getToken(TokenizeParser.WITH, 0)

        def GET(self):
            return self.getToken(TokenizeParser.GET, 0)

        def UNIT(self):
            return self.getToken(TokenizeParser.UNIT, 0)

        def EQUAL(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.EQUAL)
            else:
                return self.getToken(TokenizeParser.EQUAL, i)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def AND(self):
            return self.getToken(TokenizeParser.AND, 0)

        def private(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.PrivateContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.PrivateContext,i)


        def internal(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.InternalContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.InternalContext,i)


        def public(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.PublicContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.PublicContext,i)


        def SET(self):
            return self.getToken(TokenizeParser.SET, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_with_get_set

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterWith_get_set" ):
                listener.enterWith_get_set(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitWith_get_set" ):
                listener.exitWith_get_set(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitWith_get_set" ):
                return visitor.visitWith_get_set(self)
            else:
                return visitor.visitChildren(self)




    def with_get_set(self):

        localctx = TokenizeParser.With_get_setContext(self, self._ctx, self.state)
        self.enterRule(localctx, 156, self.RULE_with_get_set)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 700
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,58,self._ctx)
            if la_ == 1:
                self.state = 658
                self.match(TokenizeParser.WITH)

                self.state = 662
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [27]:
                    self.state = 659
                    self.private()
                    pass
                elif token in [28]:
                    self.state = 660
                    self.internal()
                    pass
                elif token in [26]:
                    self.state = 661
                    self.public()
                    pass
                elif token in [48]:
                    pass
                else:
                    pass
                self.state = 664
                self.match(TokenizeParser.GET)
                self.state = 665
                self.match(TokenizeParser.UNIT)
                self.state = 666
                self.match(TokenizeParser.EQUAL)
                self.state = 667
                self.expression()

                self.state = 669
                self.match(TokenizeParser.AND)
                self.state = 684
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,55,self._ctx)
                if la_ == 1:
                    self.state = 673
                    self._errHandler.sync(self)
                    token = self._input.LA(1)
                    if token in [27]:
                        self.state = 670
                        self.private()
                        pass
                    elif token in [28]:
                        self.state = 671
                        self.internal()
                        pass
                    elif token in [26]:
                        self.state = 672
                        self.public()
                        pass
                    elif token in [62]:
                        pass
                    else:
                        pass
                    self.state = 675
                    self.match(TokenizeParser.SET)
                    self.state = 679
                    self._errHandler.sync(self)
                    _alt = self._interp.adaptivePredict(self._input,54,self._ctx)
                    while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                        if _alt==1:
                            self.state = 676
                            self.expression() 
                        self.state = 681
                        self._errHandler.sync(self)
                        _alt = self._interp.adaptivePredict(self._input,54,self._ctx)

                    self.state = 682
                    self.match(TokenizeParser.EQUAL)
                    self.state = 683
                    self.expression()


                pass

            elif la_ == 2:
                self.state = 686
                self.match(TokenizeParser.WITH)
                self.state = 690
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,56,self._ctx)
                if la_ == 1:
                    self.state = 687
                    self.private()

                elif la_ == 2:
                    self.state = 688
                    self.internal()

                elif la_ == 3:
                    self.state = 689
                    self.public()


                self.state = 695
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,57,self._ctx)
                while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                    if _alt==1:
                        self.state = 692
                        self.expression() 
                    self.state = 697
                    self._errHandler.sync(self)
                    _alt = self._interp.adaptivePredict(self._input,57,self._ctx)

                self.state = 698
                self.match(TokenizeParser.EQUAL)
                self.state = 699
                self.expression()
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class TupleContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.COMMA)
            else:
                return self.getToken(TokenizeParser.COMMA, i)

        def getRuleIndex(self):
            return TokenizeParser.RULE_tuple

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterTuple" ):
                listener.enterTuple(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitTuple" ):
                listener.exitTuple(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitTuple" ):
                return visitor.visitTuple(self)
            else:
                return visitor.visitChildren(self)




    def tuple_(self):

        localctx = TokenizeParser.TupleContext(self, self._ctx, self.state)
        self.enterRule(localctx, 158, self.RULE_tuple)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 702
            self.match(TokenizeParser.T__5)
            self.state = 703
            self.expression()
            self.state = 706 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 704
                self.match(TokenizeParser.COMMA)
                self.state = 705
                self.expression()
                self.state = 708 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==79):
                    break

            self.state = 710
            self.match(TokenizeParser.T__6)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class WithContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def WITH(self):
            return self.getToken(TokenizeParser.WITH, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_with

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterWith" ):
                listener.enterWith(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitWith" ):
                listener.exitWith(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitWith" ):
                return visitor.visitWith(self)
            else:
                return visitor.visitChildren(self)




    def with_(self):

        localctx = TokenizeParser.WithContext(self, self._ctx, self.state)
        self.enterRule(localctx, 160, self.RULE_with)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 712
            self.match(TokenizeParser.WITH)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class RecordContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def with_(self):
            return self.getTypedRuleContext(TokenizeParser.WithContext,0)


        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def COLON(self, i:int=None):
            if i is None:
                return self.getTokens(TokenizeParser.COLON)
            else:
                return self.getToken(TokenizeParser.COLON, i)

        def dotIentifier(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.DotIentifierContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_record

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRecord" ):
                listener.enterRecord(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRecord" ):
                listener.exitRecord(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitRecord" ):
                return visitor.visitRecord(self)
            else:
                return visitor.visitChildren(self)




    def record(self):

        localctx = TokenizeParser.RecordContext(self, self._ctx, self.state)
        self.enterRule(localctx, 162, self.RULE_record)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 714
            self.match(TokenizeParser.T__1)
            self.state = 737
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,63,self._ctx)
            if la_ == 1:
                self.state = 721
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while (((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0):
                    self.state = 715
                    self.expression()
                    self.state = 716
                    self.match(TokenizeParser.COLON)
                    self.state = 717
                    self.dotIentifier()
                    self.state = 723
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)

                pass

            elif la_ == 2:
                self.state = 727
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,61,self._ctx)
                while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                    if _alt==1:
                        self.state = 724
                        self.expression() 
                    self.state = 729
                    self._errHandler.sync(self)
                    _alt = self._interp.adaptivePredict(self._input,61,self._ctx)

                self.state = 730
                self.with_()
                self.state = 734
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                while (((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0):
                    self.state = 731
                    self.expression()
                    self.state = 736
                    self._errHandler.sync(self)
                    _la = self._input.LA(1)

                pass


            self.state = 739
            self.match(TokenizeParser.T__2)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class OfContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def OF(self):
            return self.getToken(TokenizeParser.OF, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_of

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterOf" ):
                listener.enterOf(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitOf" ):
                listener.exitOf(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitOf" ):
                return visitor.visitOf(self)
            else:
                return visitor.visitChildren(self)




    def of(self):

        localctx = TokenizeParser.OfContext(self, self._ctx, self.state)
        self.enterRule(localctx, 164, self.RULE_of)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 741
            self.match(TokenizeParser.OF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class EnumContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def dotIentifier(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.DotIentifierContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,i)


        def equal(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.EqualContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.EqualContext,i)


        def of(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.OfContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.OfContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_enum

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEnum" ):
                listener.enterEnum(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEnum" ):
                listener.exitEnum(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitEnum" ):
                return visitor.visitEnum(self)
            else:
                return visitor.visitChildren(self)




    def enum(self):

        localctx = TokenizeParser.EnumContext(self, self._ctx, self.state)
        self.enterRule(localctx, 166, self.RULE_enum)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 751 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 743
                    self.match(TokenizeParser.T__12)
                    self.state = 744
                    self.dotIentifier()
                    self.state = 747
                    self._errHandler.sync(self)
                    token = self._input.LA(1)
                    if token in [93]:
                        self.state = 745
                        self.equal()
                        pass
                    elif token in [75]:
                        self.state = 746
                        self.of()
                        pass
                    else:
                        raise NoViableAltException(self)

                    self.state = 749
                    self.dotIentifier()

                else:
                    raise NoViableAltException(self)
                self.state = 753 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,65,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class InheritContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INHERIT(self):
            return self.getToken(TokenizeParser.INHERIT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_inherit

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInherit" ):
                listener.enterInherit(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInherit" ):
                listener.exitInherit(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInherit" ):
                return visitor.visitInherit(self)
            else:
                return visitor.visitChildren(self)




    def inherit(self):

        localctx = TokenizeParser.InheritContext(self, self._ctx, self.state)
        self.enterRule(localctx, 168, self.RULE_inherit)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 755
            self.match(TokenizeParser.INHERIT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class DefaultContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def DEFAULT(self):
            return self.getToken(TokenizeParser.DEFAULT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_default

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterDefault" ):
                listener.enterDefault(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitDefault" ):
                listener.exitDefault(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitDefault" ):
                return visitor.visitDefault(self)
            else:
                return visitor.visitChildren(self)




    def default(self):

        localctx = TokenizeParser.DefaultContext(self, self._ctx, self.state)
        self.enterRule(localctx, 170, self.RULE_default)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 757
            self.match(TokenizeParser.DEFAULT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class OverrideContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def OVERRIDE(self):
            return self.getToken(TokenizeParser.OVERRIDE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_override

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterOverride" ):
                listener.enterOverride(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitOverride" ):
                listener.exitOverride(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitOverride" ):
                return visitor.visitOverride(self)
            else:
                return visitor.visitChildren(self)




    def override(self):

        localctx = TokenizeParser.OverrideContext(self, self._ctx, self.state)
        self.enterRule(localctx, 172, self.RULE_override)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 759
            self.match(TokenizeParser.OVERRIDE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class AbstractContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def ABSTRACT(self):
            return self.getToken(TokenizeParser.ABSTRACT, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_abstract

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAbstract" ):
                listener.enterAbstract(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAbstract" ):
                listener.exitAbstract(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitAbstract" ):
                return visitor.visitAbstract(self)
            else:
                return visitor.visitChildren(self)




    def abstract(self):

        localctx = TokenizeParser.AbstractContext(self, self._ctx, self.state)
        self.enterRule(localctx, 174, self.RULE_abstract)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 761
            self.match(TokenizeParser.ABSTRACT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class BaseContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def BASE(self):
            return self.getToken(TokenizeParser.BASE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_base

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterBase" ):
                listener.enterBase(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitBase" ):
                listener.exitBase(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitBase" ):
                return visitor.visitBase(self)
            else:
                return visitor.visitChildren(self)




    def base(self):

        localctx = TokenizeParser.BaseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 176, self.RULE_base)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 763
            self.match(TokenizeParser.BASE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class Colon_qContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def COLON_Q(self):
            return self.getToken(TokenizeParser.COLON_Q, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_colon_q

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterColon_q" ):
                listener.enterColon_q(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitColon_q" ):
                listener.exitColon_q(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitColon_q" ):
                return visitor.visitColon_q(self)
            else:
                return visitor.visitChildren(self)




    def colon_q(self):

        localctx = TokenizeParser.Colon_qContext(self, self._ctx, self.state)
        self.enterRule(localctx, 178, self.RULE_colon_q)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 765
            self.match(TokenizeParser.COLON_Q)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class InterfaceContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def INTERFACE(self):
            return self.getToken(TokenizeParser.INTERFACE, 0)

        def getRuleIndex(self):
            return TokenizeParser.RULE_interface

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInterface" ):
                listener.enterInterface(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInterface" ):
                listener.exitInterface(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitInterface" ):
                return visitor.visitInterface(self)
            else:
                return visitor.visitChildren(self)




    def interface(self):

        localctx = TokenizeParser.InterfaceContext(self, self._ctx, self.state)
        self.enterRule(localctx, 180, self.RULE_interface)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 767
            self.match(TokenizeParser.INTERFACE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ExpressionContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def dotIentifier(self):
            return self.getTypedRuleContext(TokenizeParser.DotIentifierContext,0)


        def dot(self):
            return self.getTypedRuleContext(TokenizeParser.DotContext,0)


        def int_(self):
            return self.getTypedRuleContext(TokenizeParser.IntContext,0)


        def float_(self):
            return self.getTypedRuleContext(TokenizeParser.FloatContext,0)


        def bool_(self):
            return self.getTypedRuleContext(TokenizeParser.BoolContext,0)


        def char(self):
            return self.getTypedRuleContext(TokenizeParser.CharContext,0)


        def unit(self):
            return self.getTypedRuleContext(TokenizeParser.UnitContext,0)


        def missing_arg(self):
            return self.getTypedRuleContext(TokenizeParser.Missing_argContext,0)


        def string(self):
            return self.getTypedRuleContext(TokenizeParser.StringContext,0)


        def attribute(self):
            return self.getTypedRuleContext(TokenizeParser.AttributeContext,0)


        def let(self):
            return self.getTypedRuleContext(TokenizeParser.LetContext,0)


        def round_brackets(self):
            return self.getTypedRuleContext(TokenizeParser.Round_bracketsContext,0)


        def rec(self):
            return self.getTypedRuleContext(TokenizeParser.RecContext,0)


        def public(self):
            return self.getTypedRuleContext(TokenizeParser.PublicContext,0)


        def private(self):
            return self.getTypedRuleContext(TokenizeParser.PrivateContext,0)


        def internal(self):
            return self.getTypedRuleContext(TokenizeParser.InternalContext,0)


        def mutable(self):
            return self.getTypedRuleContext(TokenizeParser.MutableContext,0)


        def fun(self):
            return self.getTypedRuleContext(TokenizeParser.FunContext,0)


        def typezation(self):
            return self.getTypedRuleContext(TokenizeParser.TypezationContext,0)


        def if_then_elif_else(self):
            return self.getTypedRuleContext(TokenizeParser.If_then_elif_elseContext,0)


        def while_do(self):
            return self.getTypedRuleContext(TokenizeParser.While_doContext,0)


        def for_(self):
            return self.getTypedRuleContext(TokenizeParser.ForContext,0)


        def add(self):
            return self.getTypedRuleContext(TokenizeParser.AddContext,0)


        def mul(self):
            return self.getTypedRuleContext(TokenizeParser.MulContext,0)


        def div(self):
            return self.getTypedRuleContext(TokenizeParser.DivContext,0)


        def minus(self):
            return self.getTypedRuleContext(TokenizeParser.MinusContext,0)


        def pow_(self):
            return self.getTypedRuleContext(TokenizeParser.PowContext,0)


        def mod(self):
            return self.getTypedRuleContext(TokenizeParser.ModContext,0)


        def not_equal(self):
            return self.getTypedRuleContext(TokenizeParser.Not_equalContext,0)


        def less(self):
            return self.getTypedRuleContext(TokenizeParser.LessContext,0)


        def less_equal(self):
            return self.getTypedRuleContext(TokenizeParser.Less_equalContext,0)


        def greater(self):
            return self.getTypedRuleContext(TokenizeParser.GreaterContext,0)


        def greater_equal(self):
            return self.getTypedRuleContext(TokenizeParser.Greater_equalContext,0)


        def equal(self):
            return self.getTypedRuleContext(TokenizeParser.EqualContext,0)


        def and_(self):
            return self.getTypedRuleContext(TokenizeParser.AndContext,0)


        def or_(self):
            return self.getTypedRuleContext(TokenizeParser.OrContext,0)


        def lshift(self):
            return self.getTypedRuleContext(TokenizeParser.LshiftContext,0)


        def rshift(self):
            return self.getTypedRuleContext(TokenizeParser.RshiftContext,0)


        def log_mul(self):
            return self.getTypedRuleContext(TokenizeParser.Log_mulContext,0)


        def log_add(self):
            return self.getTypedRuleContext(TokenizeParser.Log_addContext,0)


        def log_xor(self):
            return self.getTypedRuleContext(TokenizeParser.Log_xorContext,0)


        def log_not(self):
            return self.getTypedRuleContext(TokenizeParser.Log_notContext,0)


        def not_(self):
            return self.getTypedRuleContext(TokenizeParser.NotContext,0)


        def pipe(self):
            return self.getTypedRuleContext(TokenizeParser.PipeContext,0)


        def compos(self):
            return self.getTypedRuleContext(TokenizeParser.ComposContext,0)


        def assign(self):
            return self.getTypedRuleContext(TokenizeParser.AssignContext,0)


        def fun_type(self):
            return self.getTypedRuleContext(TokenizeParser.Fun_typeContext,0)


        def type_(self):
            return self.getTypedRuleContext(TokenizeParser.TypeContext,0)


        def module(self):
            return self.getTypedRuleContext(TokenizeParser.ModuleContext,0)


        def open_(self):
            return self.getTypedRuleContext(TokenizeParser.OpenContext,0)


        def namespace(self):
            return self.getTypedRuleContext(TokenizeParser.NamespaceContext,0)


        def class_(self):
            return self.getTypedRuleContext(TokenizeParser.ClassContext,0)


        def do(self):
            return self.getTypedRuleContext(TokenizeParser.DoContext,0)


        def new(self):
            return self.getTypedRuleContext(TokenizeParser.NewContext,0)


        def then(self):
            return self.getTypedRuleContext(TokenizeParser.ThenContext,0)


        def seq(self):
            return self.getTypedRuleContext(TokenizeParser.SeqContext,0)


        def generator(self):
            return self.getTypedRuleContext(TokenizeParser.GeneratorContext,0)


        def list_(self):
            return self.getTypedRuleContext(TokenizeParser.ListContext,0)


        def array(self):
            return self.getTypedRuleContext(TokenizeParser.ArrayContext,0)


        def map_(self):
            return self.getTypedRuleContext(TokenizeParser.MapContext,0)


        def async_rule(self):
            return self.getTypedRuleContext(TokenizeParser.Async_ruleContext,0)


        def task(self):
            return self.getTypedRuleContext(TokenizeParser.TaskContext,0)


        def exclamation_mark(self):
            return self.getTypedRuleContext(TokenizeParser.Exclamation_markContext,0)


        def match_with(self):
            return self.getTypedRuleContext(TokenizeParser.Match_withContext,0)


        def try_with_finally(self):
            return self.getTypedRuleContext(TokenizeParser.Try_with_finallyContext,0)


        def use(self):
            return self.getTypedRuleContext(TokenizeParser.UseContext,0)


        def using(self):
            return self.getTypedRuleContext(TokenizeParser.UsingContext,0)


        def raise_(self):
            return self.getTypedRuleContext(TokenizeParser.RaiseContext,0)


        def reraise(self):
            return self.getTypedRuleContext(TokenizeParser.ReraiseContext,0)


        def failwith(self):
            return self.getTypedRuleContext(TokenizeParser.FailwithContext,0)


        def invalidArg(self):
            return self.getTypedRuleContext(TokenizeParser.InvalidArgContext,0)


        def exception_of(self):
            return self.getTypedRuleContext(TokenizeParser.Exception_ofContext,0)


        def member(self):
            return self.getTypedRuleContext(TokenizeParser.MemberContext,0)


        def val(self):
            return self.getTypedRuleContext(TokenizeParser.ValContext,0)


        def struct(self):
            return self.getTypedRuleContext(TokenizeParser.StructContext,0)


        def with_get_set(self):
            return self.getTypedRuleContext(TokenizeParser.With_get_setContext,0)


        def tuple_(self):
            return self.getTypedRuleContext(TokenizeParser.TupleContext,0)


        def with_(self):
            return self.getTypedRuleContext(TokenizeParser.WithContext,0)


        def record(self):
            return self.getTypedRuleContext(TokenizeParser.RecordContext,0)


        def enum(self):
            return self.getTypedRuleContext(TokenizeParser.EnumContext,0)


        def inherit(self):
            return self.getTypedRuleContext(TokenizeParser.InheritContext,0)


        def default(self):
            return self.getTypedRuleContext(TokenizeParser.DefaultContext,0)


        def override(self):
            return self.getTypedRuleContext(TokenizeParser.OverrideContext,0)


        def abstract(self):
            return self.getTypedRuleContext(TokenizeParser.AbstractContext,0)


        def base(self):
            return self.getTypedRuleContext(TokenizeParser.BaseContext,0)


        def colon_q(self):
            return self.getTypedRuleContext(TokenizeParser.Colon_qContext,0)


        def interface(self):
            return self.getTypedRuleContext(TokenizeParser.InterfaceContext,0)


        def getRuleIndex(self):
            return TokenizeParser.RULE_expression

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExpression" ):
                listener.enterExpression(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExpression" ):
                listener.exitExpression(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitExpression" ):
                return visitor.visitExpression(self)
            else:
                return visitor.visitChildren(self)




    def expression(self):

        localctx = TokenizeParser.ExpressionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 182, self.RULE_expression)
        try:
            self.state = 856
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,66,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 769
                self.dotIentifier()
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 770
                self.dot()
                pass

            elif la_ == 3:
                self.enterOuterAlt(localctx, 3)
                self.state = 771
                self.int_()
                pass

            elif la_ == 4:
                self.enterOuterAlt(localctx, 4)
                self.state = 772
                self.float_()
                pass

            elif la_ == 5:
                self.enterOuterAlt(localctx, 5)
                self.state = 773
                self.bool_()
                pass

            elif la_ == 6:
                self.enterOuterAlt(localctx, 6)
                self.state = 774
                self.char()
                pass

            elif la_ == 7:
                self.enterOuterAlt(localctx, 7)
                self.state = 775
                self.unit()
                pass

            elif la_ == 8:
                self.enterOuterAlt(localctx, 8)
                self.state = 776
                self.missing_arg()
                pass

            elif la_ == 9:
                self.enterOuterAlt(localctx, 9)
                self.state = 777
                self.string()
                pass

            elif la_ == 10:
                self.enterOuterAlt(localctx, 10)
                self.state = 778
                self.attribute()
                pass

            elif la_ == 11:
                self.enterOuterAlt(localctx, 11)
                self.state = 779
                self.let()
                pass

            elif la_ == 12:
                self.enterOuterAlt(localctx, 12)
                self.state = 780
                self.round_brackets()
                pass

            elif la_ == 13:
                self.enterOuterAlt(localctx, 13)
                self.state = 781
                self.rec()
                pass

            elif la_ == 14:
                self.enterOuterAlt(localctx, 14)
                self.state = 782
                self.public()
                pass

            elif la_ == 15:
                self.enterOuterAlt(localctx, 15)
                self.state = 783
                self.private()
                pass

            elif la_ == 16:
                self.enterOuterAlt(localctx, 16)
                self.state = 784
                self.internal()
                pass

            elif la_ == 17:
                self.enterOuterAlt(localctx, 17)
                self.state = 785
                self.mutable()
                pass

            elif la_ == 18:
                self.enterOuterAlt(localctx, 18)
                self.state = 786
                self.fun()
                pass

            elif la_ == 19:
                self.enterOuterAlt(localctx, 19)
                self.state = 787
                self.typezation()
                pass

            elif la_ == 20:
                self.enterOuterAlt(localctx, 20)
                self.state = 788
                self.if_then_elif_else()
                pass

            elif la_ == 21:
                self.enterOuterAlt(localctx, 21)
                self.state = 789
                self.while_do()
                pass

            elif la_ == 22:
                self.enterOuterAlt(localctx, 22)
                self.state = 790
                self.for_()
                pass

            elif la_ == 23:
                self.enterOuterAlt(localctx, 23)
                self.state = 791
                self.add()
                pass

            elif la_ == 24:
                self.enterOuterAlt(localctx, 24)
                self.state = 792
                self.mul()
                pass

            elif la_ == 25:
                self.enterOuterAlt(localctx, 25)
                self.state = 793
                self.div()
                pass

            elif la_ == 26:
                self.enterOuterAlt(localctx, 26)
                self.state = 794
                self.minus()
                pass

            elif la_ == 27:
                self.enterOuterAlt(localctx, 27)
                self.state = 795
                self.pow_()
                pass

            elif la_ == 28:
                self.enterOuterAlt(localctx, 28)
                self.state = 796
                self.mod()
                pass

            elif la_ == 29:
                self.enterOuterAlt(localctx, 29)
                self.state = 797
                self.not_equal()
                pass

            elif la_ == 30:
                self.enterOuterAlt(localctx, 30)
                self.state = 798
                self.less()
                pass

            elif la_ == 31:
                self.enterOuterAlt(localctx, 31)
                self.state = 799
                self.less_equal()
                pass

            elif la_ == 32:
                self.enterOuterAlt(localctx, 32)
                self.state = 800
                self.greater()
                pass

            elif la_ == 33:
                self.enterOuterAlt(localctx, 33)
                self.state = 801
                self.greater_equal()
                pass

            elif la_ == 34:
                self.enterOuterAlt(localctx, 34)
                self.state = 802
                self.equal()
                pass

            elif la_ == 35:
                self.enterOuterAlt(localctx, 35)
                self.state = 803
                self.and_()
                pass

            elif la_ == 36:
                self.enterOuterAlt(localctx, 36)
                self.state = 804
                self.or_()
                pass

            elif la_ == 37:
                self.enterOuterAlt(localctx, 37)
                self.state = 805
                self.lshift()
                pass

            elif la_ == 38:
                self.enterOuterAlt(localctx, 38)
                self.state = 806
                self.rshift()
                pass

            elif la_ == 39:
                self.enterOuterAlt(localctx, 39)
                self.state = 807
                self.log_mul()
                pass

            elif la_ == 40:
                self.enterOuterAlt(localctx, 40)
                self.state = 808
                self.log_add()
                pass

            elif la_ == 41:
                self.enterOuterAlt(localctx, 41)
                self.state = 809
                self.log_xor()
                pass

            elif la_ == 42:
                self.enterOuterAlt(localctx, 42)
                self.state = 810
                self.log_not()
                pass

            elif la_ == 43:
                self.enterOuterAlt(localctx, 43)
                self.state = 811
                self.not_()
                pass

            elif la_ == 44:
                self.enterOuterAlt(localctx, 44)
                self.state = 812
                self.pipe()
                pass

            elif la_ == 45:
                self.enterOuterAlt(localctx, 45)
                self.state = 813
                self.compos()
                pass

            elif la_ == 46:
                self.enterOuterAlt(localctx, 46)
                self.state = 814
                self.assign()
                pass

            elif la_ == 47:
                self.enterOuterAlt(localctx, 47)
                self.state = 815
                self.fun_type()
                pass

            elif la_ == 48:
                self.enterOuterAlt(localctx, 48)
                self.state = 816
                self.type_()
                pass

            elif la_ == 49:
                self.enterOuterAlt(localctx, 49)
                self.state = 817
                self.module()
                pass

            elif la_ == 50:
                self.enterOuterAlt(localctx, 50)
                self.state = 818
                self.open_()
                pass

            elif la_ == 51:
                self.enterOuterAlt(localctx, 51)
                self.state = 819
                self.namespace()
                pass

            elif la_ == 52:
                self.enterOuterAlt(localctx, 52)
                self.state = 820
                self.class_()
                pass

            elif la_ == 53:
                self.enterOuterAlt(localctx, 53)
                self.state = 821
                self.do()
                pass

            elif la_ == 54:
                self.enterOuterAlt(localctx, 54)
                self.state = 822
                self.new()
                pass

            elif la_ == 55:
                self.enterOuterAlt(localctx, 55)
                self.state = 823
                self.then()
                pass

            elif la_ == 56:
                self.enterOuterAlt(localctx, 56)
                self.state = 824
                self.seq()
                pass

            elif la_ == 57:
                self.enterOuterAlt(localctx, 57)
                self.state = 825
                self.generator()
                pass

            elif la_ == 58:
                self.enterOuterAlt(localctx, 58)
                self.state = 826
                self.list_()
                pass

            elif la_ == 59:
                self.enterOuterAlt(localctx, 59)
                self.state = 827
                self.array()
                pass

            elif la_ == 60:
                self.enterOuterAlt(localctx, 60)
                self.state = 828
                self.map_()
                pass

            elif la_ == 61:
                self.enterOuterAlt(localctx, 61)
                self.state = 829
                self.async_rule()
                pass

            elif la_ == 62:
                self.enterOuterAlt(localctx, 62)
                self.state = 830
                self.task()
                pass

            elif la_ == 63:
                self.enterOuterAlt(localctx, 63)
                self.state = 831
                self.exclamation_mark()
                pass

            elif la_ == 64:
                self.enterOuterAlt(localctx, 64)
                self.state = 832
                self.match_with()
                pass

            elif la_ == 65:
                self.enterOuterAlt(localctx, 65)
                self.state = 833
                self.try_with_finally()
                pass

            elif la_ == 66:
                self.enterOuterAlt(localctx, 66)
                self.state = 834
                self.use()
                pass

            elif la_ == 67:
                self.enterOuterAlt(localctx, 67)
                self.state = 835
                self.using()
                pass

            elif la_ == 68:
                self.enterOuterAlt(localctx, 68)
                self.state = 836
                self.raise_()
                pass

            elif la_ == 69:
                self.enterOuterAlt(localctx, 69)
                self.state = 837
                self.reraise()
                pass

            elif la_ == 70:
                self.enterOuterAlt(localctx, 70)
                self.state = 838
                self.failwith()
                pass

            elif la_ == 71:
                self.enterOuterAlt(localctx, 71)
                self.state = 839
                self.invalidArg()
                pass

            elif la_ == 72:
                self.enterOuterAlt(localctx, 72)
                self.state = 840
                self.exception_of()
                pass

            elif la_ == 73:
                self.enterOuterAlt(localctx, 73)
                self.state = 841
                self.member()
                pass

            elif la_ == 74:
                self.enterOuterAlt(localctx, 74)
                self.state = 842
                self.val()
                pass

            elif la_ == 75:
                self.enterOuterAlt(localctx, 75)
                self.state = 843
                self.struct()
                pass

            elif la_ == 76:
                self.enterOuterAlt(localctx, 76)
                self.state = 844
                self.with_get_set()
                pass

            elif la_ == 77:
                self.enterOuterAlt(localctx, 77)
                self.state = 845
                self.tuple_()
                pass

            elif la_ == 78:
                self.enterOuterAlt(localctx, 78)
                self.state = 846
                self.with_()
                pass

            elif la_ == 79:
                self.enterOuterAlt(localctx, 79)
                self.state = 847
                self.record()
                pass

            elif la_ == 80:
                self.enterOuterAlt(localctx, 80)
                self.state = 848
                self.enum()
                pass

            elif la_ == 81:
                self.enterOuterAlt(localctx, 81)
                self.state = 849
                self.inherit()
                pass

            elif la_ == 82:
                self.enterOuterAlt(localctx, 82)
                self.state = 850
                self.default()
                pass

            elif la_ == 83:
                self.enterOuterAlt(localctx, 83)
                self.state = 851
                self.override()
                pass

            elif la_ == 84:
                self.enterOuterAlt(localctx, 84)
                self.state = 852
                self.abstract()
                pass

            elif la_ == 85:
                self.enterOuterAlt(localctx, 85)
                self.state = 853
                self.base()
                pass

            elif la_ == 86:
                self.enterOuterAlt(localctx, 86)
                self.state = 854
                self.colon_q()
                pass

            elif la_ == 87:
                self.enterOuterAlt(localctx, 87)
                self.state = 855
                self.interface()
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx


    class ExprsContext(ParserRuleContext):
        __slots__ = 'parser'

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def EOF(self):
            return self.getToken(TokenizeParser.EOF, 0)

        def expression(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(TokenizeParser.ExpressionContext)
            else:
                return self.getTypedRuleContext(TokenizeParser.ExpressionContext,i)


        def getRuleIndex(self):
            return TokenizeParser.RULE_exprs

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExprs" ):
                listener.enterExprs(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExprs" ):
                listener.exitExprs(self)

        def accept(self, visitor:ParseTreeVisitor):
            if hasattr( visitor, "visitExprs" ):
                return visitor.visitExprs(self)
            else:
                return visitor.visitChildren(self)




    def exprs(self):

        localctx = TokenizeParser.ExprsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 184, self.RULE_exprs)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 861
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & -4900286071009564330) != 0) or ((((_la - 64)) & ~0x3f) == 0 and ((1 << (_la - 64)) & 35184369883103) != 0):
                self.state = 858
                self.expression()
                self.state = 863
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 864
            self.match(TokenizeParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





